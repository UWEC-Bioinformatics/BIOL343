{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 8 Homework\n",
    "\n",
    "***Due (pushed to your GitHub branch) on 11/8 by 11:59 pm***\n",
    "\n",
    "## Mark duplicates\n",
    "\n",
    "Use Picard Tools to mark the duplicates of the HISAT and STAR alignments. Store the logs in a new directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%mkdir logs_lemons\n",
    "%mkdir dedup_lemons\n",
    "\n",
    "!picard MarkDuplicates -I ../6_alignment/alignment_lemons/star/Aligned.sortedByCoord.out.bam -M logs_lemons/star_duplicates -O dedup_lemons/star.bam --VALIDATION_STRINGENCY SILENT\n",
    "\n",
    "!picard MarkDuplicates -I ../6_alignment/alignment_lemons/hisat/merged.bam -M logs_lemons/hisat_duplicates -O dedup_lemons/hisat.bam --VALIDATION_STRINGENCY SILENT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting\n",
    "\n",
    "Use featureCounts to count reads. You may need to explicitly set the features and meta-features with `-t` and `-g`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!featureCounts -T 32 \\\n",
    "    dedup_lemons/star.bam \\\n",
    "    -T 32 \\\n",
    "    --byReadGroup \\\n",
    "    -s 1 \\\n",
    "    --ignoreDup \\\n",
    "    -M \\\n",
    "    --fraction \\\n",
    "    -a ../2_genome_exploration/lemons/lemon_annotations.gtf \\\n",
    "    -o star_counts.tsv \\\n",
    "    --verbose\n",
    "\n",
    "!featureCounts -T 32 \\\n",
    "    dedup_lemons/hisat.bam \\\n",
    "    -T 32 \\\n",
    "    --byReadGroup \\\n",
    "    -s 1 \\\n",
    "    --ignoreDup \\\n",
    "    -M \\\n",
    "    --fraction \\\n",
    "    -a ../2_genome_exploration/lemons/lemon_annotations.gtf \\\n",
    "    -o hisat_counts.tsv \\\n",
    "    --verbose"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report\n",
    "\n",
    "Use MultiQC to aggregate a report that incorporates all steps of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!multiqc --force -d ../5_fastq/fastq_lemons/qc/ ../5_fastq/trimmed_lemons/qc/ ../6_alignment/alignment_lemons ../7-alignment_qc -n multiqc_report_lemons.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snakemake Pipeline (optional)\n",
    "\n",
    "1. Copy your `Snakefile` and `config.yaml` from `7_alignment_qc` to `8_counting`.  \n",
    "2. In the `Snakefile`, add the following rules:  \n",
    "    a. `mark_duplicates` - use Picard Tools to mark the duplicate reads in the STAR and HISAT alignments.  \n",
    "    b. `count` - use featureCounts to count reads in the alignments with duplicates marked.  \n",
    "    c. `report` - use `multiqc` to aggregate all QC data into a single report. This should be an update of the report from the previous week's homework.  \n",
    "\n",
    "This `Snakefile` should not use any `wrappers` because we already have the relevant software installed in the `biol343` conda environment. The pipeline should run to completion when any instructor or classmate runs `snakemake --use-conda`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
