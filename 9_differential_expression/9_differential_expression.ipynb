{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differential expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "\n",
    "from pydeseq2.dds import DeseqDataSet\n",
    "from pydeseq2.default_inference import DefaultInference\n",
    "from pydeseq2.ds import DeseqStats\n",
    "from pydeseq2.utils import load_example_data\n",
    "\n",
    "\n",
    "OUTPUT_PATH = \"tmp/\"\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QC on raw counts\n",
    "\n",
    "Before we do any differential expression analysis, it's good to do some QC on the count data to ensure the sequencing samples cluster as expected. For our experiment, we expect 2 clusters (PZQ vs. Control) each with 5 points.\n",
    "\n",
    "### Gene filtering based on total read count and the number of samples the gene is found in\n",
    "\n",
    "Before we do anything, we are going to filter the count data to remove genes with low total expression values (anything less than 10 is not going to be informative) and genes that were only expressed in 3 or fewer samples. First, we read in the counts data and convert numeric columns to integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "counts_df = pd.read_csv(\"/data/classes/2025/fall/biol343/course_files/counts/star_counts.tsv\", sep=\"\\t\", header=1)\n",
    "counts_df.iloc[:, 6:16] = counts_df.iloc[:, 6:16].astype('int')\n",
    "counts_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we do the filtering. The first operation will sum the expression across all samples and remove any gene that had a total count of less than or equal to 10. The second operation will count each sample that had counts >0 of each gene. Any gene that wasn't expressed in >3 samples will be removed entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only the Geneid and count columns\n",
    "star_cols = [c for c in counts_df.columns if \"star.bam\" in c]\n",
    "counts_subset = counts_df[[\"Geneid\"] + star_cols].copy()\n",
    "\n",
    "# rename count columns\n",
    "prefix = \"/data/classes/2025/fall/biol343/course_files/dedup/star.bam:\"\n",
    "def strip_prefix(name: str) -> str:\n",
    "    return name.replace(prefix, \"\")\n",
    "counts_subset.rename(columns={c: strip_prefix(c) for c in star_cols}, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to sum the counts (row-wise). This will create the new column `total_counts`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# compute total_counts across numeric sample columns (row-wise)\n",
    "# treat NA as 0, matching na.rm = TRUE\n",
    "sample_cols = [c for c in counts_subset.columns if c != \"Geneid\"]\n",
    "counts_numeric = counts_subset[sample_cols].apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "counts_subset[\"total_counts\"] = counts_numeric.sum(axis=1)\n",
    "\n",
    "counts_subset "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter to only keep genes with `total_counts` >10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_summary = counts_subset.loc[counts_subset[\"total_counts\"] >= 10].copy()\n",
    "counts_summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that previously, we had 9,920 rows. Each row is a gene. Now, we have 9,587 rows. We removed about 350 lowly expressed genes. \n",
    "\n",
    "We're now going to find genes that have a count of >0 in <3 samples and remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_counts_mask = counts_numeric.loc[counts_summary.index] > 0\n",
    "n_positive_samples = positive_counts_mask.sum(axis=1)\n",
    "genes_to_remove = counts_summary.loc[n_positive_samples <= 3, \"Geneid\"]\n",
    "genes_to_remove"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 genes are going to be removed. Let's remove them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_filt = (\n",
    "    counts_summary.loc[~counts_summary[\"Geneid\"].isin(genes_to_remove)]\n",
    "    .sort_values(by=\"Geneid\")\n",
    "    .drop(columns=[\"total_counts\"])\n",
    ")\n",
    "counts_filt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This filtered dataset of 9577 genes will be used for all downstream analyses. \n",
    "\n",
    "### Clustering for QC\n",
    "First, we'll measure the Euclidean distance between each sample and then plot the results as a heatmap. We'll first convert the data from a data frame to a matrix, and then measure the distance.\n",
    "\n",
    "We'll first get the coutns and create a matrix object and set the rownames as Geneid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "count_cols = [c for c in counts_filt.columns if c != \"Geneid\"]\n",
    "counts_m = counts_filt[count_cols].apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "counts_m.index = counts_filt[\"Geneid\"].values\n",
    "counts_m"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use NumPy to calculate the distances. We have to transpose the matrix (samples x genes instead of genes x samples), then we'll calculate the distances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "X = counts_m.to_numpy().T  # samples x genes\n",
    "sample_names = counts_m.columns.tolist()\n",
    "\n",
    "D = pairwise_distances(X, metric=\"euclidean\")\n",
    "dists_df = pd.DataFrame(D, index=sample_names, columns=sample_names)\n",
    "\n",
    "dists_df.round(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the distance matrix, which shows how similar in expression each sample is to every other samples. QC involves us ensuring that the PZQ samples are all closer to each other than to the CTRL samples. Here's a heatmap showing that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.clustermap(\n",
    "    dists_df,\n",
    "    cmap=\"viridis\",\n",
    "    method=\"average\",\n",
    "    z_score=None,\n",
    "    standard_scale=None,\n",
    "    figsize=(8, 8)\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clearly see two clusters: one for treated samples and one for control samples. Let's see what the PCA looks like. \n",
    "\n",
    "We first log-transform the count data and scale the data across samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# log transform and transpose to samples x genes\n",
    "X = np.log10(counts_m.to_numpy() + 1.0).T  # shape: n_samples x n_genes\n",
    "sample_names = counts_m.columns.tolist()\n",
    "\n",
    "# scale features (genes) across samples\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're also going to build a DataFrame that includes sample metadata. This will be used to annotate the PCA and will also used for DESeq2 analyses later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ids = list(counts_m.columns)\n",
    "\n",
    "# create a DataFrame with sample_id\n",
    "metadata = pd.DataFrame({\"sample_id\": sample_ids})\n",
    "parts = metadata[\"sample_id\"].str.split(\"_\", expand=True)\n",
    "parts.columns = [\"stage\", \"treatment\", \"rep\"]\n",
    "\n",
    "metadata = pd.concat([metadata, parts], axis=1)\n",
    "metadata = metadata.set_index(\"sample_id\")\n",
    "metadata = metadata[[\"treatment\", \"rep\"]]\n",
    "metadata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we run the PCA and plot the points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=10, random_state=0)  \n",
    "scores = pca.fit_transform(X_scaled)        \n",
    "# explained = pca.explained_variance_ratio_\n",
    "\n",
    "scores_df = pd.DataFrame(\n",
    "    scores[:, :2],  # PC1 and PC2 for plotting\n",
    "    index=sample_names,\n",
    "    columns=[\"PC1\", \"PC2\"]\n",
    ")\n",
    "\n",
    "plot_df = scores_df.join(metadata[[\"treatment\", \"rep\"]], how=\"left\")\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(7, 6))\n",
    "sns.scatterplot(\n",
    "    data=plot_df,\n",
    "    x=\"PC1\",\n",
    "    y=\"PC2\",\n",
    "    hue=\"treatment\",     # color by tissue\n",
    "    style=\"rep\", \n",
    "    s=80\n",
    ")\n",
    "plt.title(\"PCA: PC1 vs PC2\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\", borderaxespad=0.)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! This is exactly what we want. Two clear clusters based on the treatment. This means all 10 samples should be included in our differential expression analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differential expression analysis\n",
    "To perform differential expression analysis, DESeq2 requires two types of input:\n",
    "\n",
    "1. A count matrix of shape ‘number of samples’ x ‘number of genes’, containing read counts (non-negative integers) \n",
    "2. Metadata (or “column” data) of shape ‘number of samples’ x ‘number of variables’, containing sample annotations that will be used to split the data in cohorts.\n",
    "\n",
    "The output of featureCounts needs to be converted to a matrix, the column names should be simplified, and a few unnecessary columns need to be removed. We also made the metadata DataFrame earlier as well.\n",
    "\n",
    "To be sure, we'll check to confirm the metadata and count columns from `counts_m` correspond:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(metadata.index) == set(counts_m.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single factor analyses\n",
    "\n",
    "DESeq2 allows for single factorial analyses (only one independent variable, i.e., just treamtent) or multifactorial analyses (more than independent variable, which is not applicaable for this dataset). We will analyze the data to see if there are differences between CTRL and PZQ worms. To do so, we create a `DeseqDataSet` (or DDS object), which incorporates the counts and the metadata. We can then run the `deseq()` method on the DDS object to fit dispersions and log-fold changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyDESeq2 single-factor (combined) setup, mirroring your R snippet\n",
    "\n",
    "from pydeseq2.dds import DeseqDataSet\n",
    "from pydeseq2.default_inference import DefaultInference\n",
    "\n",
    "inference = DefaultInference(n_cpus=32)\n",
    "\n",
    "dds = DeseqDataSet(\n",
    "    counts=counts_m.T,        # genes x samples, integer counts, transposed\n",
    "    metadata=metadata,         # DataFrame indexed by sample_id\n",
    "    design_factors=\"treatment\",  # single factor name present in metadata\n",
    "    refit_cooks=True,\n",
    "    inference=inference\n",
    ")\n",
    "\n",
    "dds\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DDS object is based on the AnnData object. Like any Python objects, we can access the fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dds.obsm)\n",
    "dds.obsm['design_matrix']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the `deseq2()` method, which fits the dispersion and log-fold changes and therefore now adds new fields to the DDS object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dds.deseq2()\n",
    "dds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for example, we can access the gene-level log-fold changes (LFCs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dds.varm[\"LFC\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DDS object with the dispersions and LFCs allow us to perform statistical tests. The `DeseqStats` class includes the DDS object and will allow for the calculation of p-values and adjusted p-values. These data are stored in `results_df`. We can view these data with the `.summary()` methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_res = DeseqStats(dds, inference=inference)\n",
    "stat_res.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the featured differentially expressed genes from the paper was the ABC transporter (which detoxifies drugs by transporting them out of the cell) gene Smp_089200, which decreased in expression after drug treatment. We can search for that gene to see we reproduce the finding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = stat_res.results_df\n",
    "summary['gene_id'] = summary.index\n",
    "summary = summary.reset_index()\n",
    "summary.loc[summary['gene_id'] == 'Smp_089200']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the L2FC of Smp_089200 is -1, which means its expression is half as much in treated samples as in control samples (i.e, a 2^-1). This is consistent with the figure from the paper:\n",
    "\n",
    "<img src=\"../8_counting/assets/example_genes.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volcano plots\n",
    "\n",
    "Typically in RNA-seq analyses, we are interested in genes that are significantly differentially expressed (padj <0.05) and those that have large differences (maybe log two fold change > 2, which is a four-fold change). Volcano plots are a good way to visualize all the genes that satisfy both conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = summary['log2FoldChange'].to_numpy()\n",
    "y = -np.log10(summary['padj'].to_numpy())\n",
    "\n",
    "sig = (summary['padj'] < 0.05) & (summary['log2FoldChange'].abs() >= 2)\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.axhline(-np.log10(0.05), color='red', linestyle='--', linewidth=1)\n",
    "plt.axvline(2, color='gray', linestyle='--', linewidth=1)\n",
    "plt.axvline(-2, color='gray', linestyle='--', linewidth=1)\n",
    "plt.scatter(x[~sig], y[~sig], s=3, color='steelblue', alpha=0.7, label='NS')\n",
    "plt.scatter(x[sig], y[sig], s=6, color='tomato', alpha=0.8, label='DE (padj<0.05 & |LFC|≥2)')\n",
    "plt.legend(frameon=False)\n",
    "plt.xlabel('log2FoldChange'); plt.ylabel('-log10(padj)')\n",
    "plt.title('Volcano plot'); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a plot like this, the higher points represent genes that are most likely to be truly significantly differentially expressed (a small p-value). The points far to the right or left represent genes that have large expression differences (fold changes) between CTRL and PZQ. The points in the top right/left areas (red), then, are the genes in which we're interested."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QC on transformed data\n",
    "\n",
    "Now what we have the `dds` object, we can do another PCA on counts that have been normalized and transformed. The first PCA we did was on raw counts, but it's often helpful to see the PCA clusters on normalized/transformed counts. We first transform the read counts with DESeq2's variance-stabilizing transformation, which will add a new `vst_counts` layer to the `dds` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dds.vst()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run the same PCA code, but this time using the normalized/transformed counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dds.layers[\"vst_counts\"]   # shape: (samples, genes)\n",
    "obs = dds.obs  # sample metadata DataFrame\n",
    "\n",
    "pca = PCA(n_components=10, random_state=0)  \n",
    "scores = pca.fit_transform(X)        \n",
    "# explained = pca.explained_variance_ratio_\n",
    "\n",
    "scores_df = pd.DataFrame(\n",
    "    scores[:, :2],  # PC1 and PC2 for plotting\n",
    "    index=sample_names,\n",
    "    columns=[\"PC1\", \"PC2\"]\n",
    ")\n",
    "\n",
    "plot_df = scores_df.join(metadata[[\"treatment\", \"rep\"]], how=\"left\")\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(7, 6))\n",
    "sns.scatterplot(\n",
    "    data=plot_df,\n",
    "    x=\"PC1\",\n",
    "    y=\"PC2\",\n",
    "    hue=\"treatment\",     # color by tissue\n",
    "    style=\"rep\", \n",
    "    s=80\n",
    ")\n",
    "plt.title(\"PCA: PC1 vs PC2\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\", borderaxespad=0.)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clustering is similar to the previous PCA, but now the spread is much less (the x and y axes have smaller ranges.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biol343_temp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
