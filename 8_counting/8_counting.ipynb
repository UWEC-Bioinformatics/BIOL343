{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating counts from an alignment\n",
    "\n",
    "Counting is more straightforward than alignment, but it's still very important and a bioinformatician has to think carefully about how to go about this process. Remember, identifying differnetially expressed genes relies upon the statistical comparison of the number of reads assigned to genes, compared among samples. \n",
    "\n",
    "We will be using `featureCounts` to count reads. `StringTie` is another popular counter. Install `subread` (of which `featureCounts` is a submodule) with `conda install bioconda::subread`.\n",
    "\n",
    "After installing, take a look at the `featureCounts` manual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Version 2.0.6\n",
      "\n",
      "Usage: featureCounts [options] -a <annotation_file> -o <output_file> input_file1 [input_file2] ... \n",
      "\n",
      "## Mandatory arguments:\n",
      "\n",
      "  -a <string>         Name of an annotation file. GTF/GFF format by default. See\n",
      "                      -F option for more format information. Inbuilt annotations\n",
      "                      (SAF format) is available in 'annotation' directory of the\n",
      "                      package. Gzipped file is also accepted.\n",
      "\n",
      "  -o <string>         Name of output file including read counts. A separate file\n",
      "                      including summary statistics of counting results is also\n",
      "                      included in the output ('<string>.summary'). Both files\n",
      "                      are in tab delimited format.\n",
      "\n",
      "  input_file1 [input_file2] ...   A list of SAM or BAM format files. They can be\n",
      "                      either name or location sorted. If no files provided,\n",
      "                      <stdin> input is expected. Location-sorted paired-end reads\n",
      "                      are automatically sorted by read names.\n",
      "\n",
      "## Optional arguments:\n",
      "# Annotation\n",
      "\n",
      "  -F <string>         Specify format of the provided annotation file. Acceptable\n",
      "                      formats include 'GTF' (or compatible GFF format) and\n",
      "                      'SAF'. 'GTF' by default.  For SAF format, please refer to\n",
      "                      Users Guide.\n",
      "\n",
      "  -t <string>         Specify feature type(s) in a GTF annotation. If multiple\n",
      "                      types are provided, they should be separated by ',' with\n",
      "                      no space in between. 'exon' by default. Rows in the\n",
      "                      annotation with a matched feature will be extracted and\n",
      "                      used for read mapping. \n",
      "\n",
      "  -g <string>         Specify attribute type in GTF annotation. 'gene_id' by \n",
      "                      default. Meta-features used for read counting will be \n",
      "                      extracted from annotation using the provided value.\n",
      "\n",
      "  --extraAttributes   Extract extra attribute types from the provided GTF\n",
      "                      annotation and include them in the counting output. These\n",
      "                      attribute types will not be used to group features. If\n",
      "                      more than one attribute type is provided they should be\n",
      "                      separated by comma.\n",
      "\n",
      "  -A <string>         Provide a chromosome name alias file to match chr names in\n",
      "                      annotation with those in the reads. This should be a two-\n",
      "                      column comma-delimited text file. Its first column should\n",
      "                      include chr names in the annotation and its second column\n",
      "                      should include chr names in the reads. Chr names are case\n",
      "                      sensitive. No column header should be included in the\n",
      "                      file.\n",
      "\n",
      "# Level of summarization\n",
      "\n",
      "  -f                  Perform read counting at feature level (eg. counting \n",
      "                      reads for exons rather than genes).\n",
      "\n",
      "# Overlap between reads and features\n",
      "\n",
      "  -O                  Assign reads to all their overlapping meta-features (or \n",
      "                      features if -f is specified).\n",
      "\n",
      "  --minOverlap <int>  Minimum number of overlapping bases in a read that is\n",
      "                      required for read assignment. 1 by default. Number of\n",
      "                      overlapping bases is counted from both reads if paired\n",
      "                      end. If a negative value is provided, then a gap of up\n",
      "                      to specified size will be allowed between read and the\n",
      "                      feature that the read is assigned to.\n",
      "\n",
      "  --fracOverlap <float> Minimum fraction of overlapping bases in a read that is\n",
      "                      required for read assignment. Value should be within range\n",
      "                      [0,1]. 0 by default. Number of overlapping bases is\n",
      "                      counted from both reads if paired end. Both this option\n",
      "                      and '--minOverlap' option need to be satisfied for read\n",
      "                      assignment.\n",
      "\n",
      "  --fracOverlapFeature <float> Minimum fraction of overlapping bases in a\n",
      "                      feature that is required for read assignment. Value\n",
      "                      should be within range [0,1]. 0 by default.\n",
      "\n",
      "  --largestOverlap    Assign reads to a meta-feature/feature that has the \n",
      "                      largest number of overlapping bases.\n",
      "\n",
      "  --nonOverlap <int>  Maximum number of non-overlapping bases in a read (or a\n",
      "                      read pair) that is allowed when being assigned to a\n",
      "                      feature. No limit is set by default.\n",
      "\n",
      "  --nonOverlapFeature <int> Maximum number of non-overlapping bases in a feature\n",
      "                      that is allowed in read assignment. No limit is set by\n",
      "                      default.\n",
      "\n",
      "  --readExtension5 <int> Reads are extended upstream by <int> bases from their\n",
      "                      5' end.\n",
      "\n",
      "  --readExtension3 <int> Reads are extended upstream by <int> bases from their\n",
      "                      3' end.\n",
      "\n",
      "  --read2pos <5:3>    Reduce reads to their 5' most base or 3' most base. Read\n",
      "                      counting is then performed based on the single base the \n",
      "                      read is reduced to.\n",
      "\n",
      "# Multi-mapping reads\n",
      "\n",
      "  -M                  Multi-mapping reads will also be counted. For a multi-\n",
      "                      mapping read, all its reported alignments will be \n",
      "                      counted. The 'NH' tag in BAM/SAM input is used to detect \n",
      "                      multi-mapping reads.\n",
      "\n",
      "# Fractional counting\n",
      "\n",
      "  --fraction          Assign fractional counts to features. This option must\n",
      "                      be used together with '-M' or '-O' or both. When '-M' is\n",
      "                      specified, each reported alignment from a multi-mapping\n",
      "                      read (identified via 'NH' tag) will carry a fractional\n",
      "                      count of 1/x, instead of 1 (one), where x is the total\n",
      "                      number of alignments reported for the same read. When '-O'\n",
      "                      is specified, each overlapping feature will receive a\n",
      "                      fractional count of 1/y, where y is the total number of\n",
      "                      features overlapping with the read. When both '-M' and\n",
      "                      '-O' are specified, each alignment will carry a fractional\n",
      "                      count of 1/(x*y).\n",
      "\n",
      "# Read filtering\n",
      "\n",
      "  -Q <int>            The minimum mapping quality score a read must satisfy in\n",
      "                      order to be counted. For paired-end reads, at least one\n",
      "                      end should satisfy this criteria. 0 by default.\n",
      "\n",
      "  --splitOnly         Count split alignments only (ie. alignments with CIGAR\n",
      "                      string containing 'N'). An example of split alignments is\n",
      "                      exon-spanning reads in RNA-seq data.\n",
      "\n",
      "  --nonSplitOnly      If specified, only non-split alignments (CIGAR strings do\n",
      "                      not contain letter 'N') will be counted. All the other\n",
      "                      alignments will be ignored.\n",
      "\n",
      "  --primary           Count primary alignments only. Primary alignments are \n",
      "                      identified using bit 0x100 in SAM/BAM FLAG field.\n",
      "\n",
      "  --ignoreDup         Ignore duplicate reads in read counting. Duplicate reads \n",
      "                      are identified using bit Ox400 in BAM/SAM FLAG field. The \n",
      "                      whole read pair is ignored if one of the reads is a \n",
      "                      duplicate read for paired end data.\n",
      "\n",
      "# Strandness\n",
      "\n",
      "  -s <int or string>  Perform strand-specific read counting. A single integer\n",
      "                      value (applied to all input files) or a string of comma-\n",
      "                      separated values (applied to each corresponding input\n",
      "                      file) should be provided. Possible values include:\n",
      "                      0 (unstranded), 1 (stranded) and 2 (reversely stranded).\n",
      "                      Default value is 0 (ie. unstranded read counting carried\n",
      "                      out for all input files).\n",
      "\n",
      "# Exon-exon junctions\n",
      "\n",
      "  -J                  Count number of reads supporting each exon-exon junction.\n",
      "                      Junctions were identified from all the exon-spanning reads\n",
      "                      in the input (containing 'N' in CIGAR string). Counting\n",
      "                      results are saved to a file named '<output_file>.jcounts'\n",
      "\n",
      "  -G <string>         Provide the name of a FASTA-format file that contains the\n",
      "                      reference sequences used in read mapping that produced the\n",
      "                      provided SAM/BAM files. This optional argument can be used\n",
      "                      with '-J' option to improve read counting for junctions.\n",
      "\n",
      "# Parameters specific to paired end reads\n",
      "\n",
      "  -p                  If specified, libraries are assumed to contain paired-end\n",
      "                      reads. For any library that contains paired-end reads, the\n",
      "                      'countReadPairs' parameter controls if read pairs or reads\n",
      "                      should be counted.\n",
      "\n",
      "  --countReadPairs    If specified, fragments (or templates) will be counted\n",
      "                      instead of reads. This option is only applicable for\n",
      "                      paired-end reads. For single-end data, it is ignored.\n",
      "\n",
      "  -B                  Only count read pairs that have both ends aligned.\n",
      "\n",
      "  -P                  Check validity of paired-end distance when counting read \n",
      "                      pairs. Use -d and -D to set thresholds.\n",
      "\n",
      "  -d <int>            Minimum fragment/template length, 50 by default.\n",
      "\n",
      "  -D <int>            Maximum fragment/template length, 600 by default.\n",
      "\n",
      "  -C                  Do not count read pairs that have their two ends mapping \n",
      "                      to different chromosomes or mapping to same chromosome \n",
      "                      but on different strands.\n",
      "\n",
      "  --donotsort         Do not sort reads in BAM/SAM input. Note that reads from \n",
      "                      the same pair are required to be located next to each \n",
      "                      other in the input.\n",
      "\n",
      "# Number of CPU threads\n",
      "\n",
      "  -T <int>            Number of the threads. 1 by default.\n",
      "\n",
      "# Read groups\n",
      "\n",
      "  --byReadGroup       Assign reads by read group. \"RG\" tag is required to be\n",
      "                      present in the input BAM/SAM files.\n",
      "                      \n",
      "\n",
      "# Long reads\n",
      "\n",
      "  -L                  Count long reads such as Nanopore and PacBio reads. Long\n",
      "                      read counting can only run in one thread and only reads\n",
      "                      (not read-pairs) can be counted. There is no limitation on\n",
      "                      the number of 'M' operations allowed in a CIGAR string in\n",
      "                      long read counting.\n",
      "\n",
      "# Assignment results for each read\n",
      "\n",
      "  -R <format>         Output detailed assignment results for each read or read-\n",
      "                      pair. Results are saved to a file that is in one of the\n",
      "                      following formats: CORE, SAM and BAM. See Users Guide for\n",
      "                      more info about these formats.\n",
      "\n",
      "  --Rpath <string>    Specify a directory to save the detailed assignment\n",
      "                      results. If unspecified, the directory where counting\n",
      "                      results are saved is used.\n",
      "\n",
      "# Miscellaneous\n",
      "\n",
      "  --tmpDir <string>   Directory under which intermediate files are saved (later\n",
      "                      removed). By default, intermediate files will be saved to\n",
      "                      the directory specified in '-o' argument.\n",
      "\n",
      "  --maxMOp <int>      Maximum number of 'M' operations allowed in a CIGAR\n",
      "                      string. 10 by default. Both 'X' and '=' are treated as 'M'\n",
      "                      and adjacent 'M' operations are merged in the CIGAR\n",
      "                      string.\n",
      "\n",
      "  --verbose           Output verbose information for debugging, such as un-\n",
      "                      matched chromosome/contig names.\n",
      "\n",
      "  -v                  Output version of the program.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!featureCounts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are analyzing data produced in the [Winners vs. Losers paper](https://journals.plos.org/plospathogens/article?id=10.1371/journal.ppat.1012268), which analyzed the expression differences between schistosome eggs that were trapped in the liver and eggs that were trapped in the intestine. Luckily for us, the methods section contains a few details about their use of `featureCounts`:\n",
    "\n",
    "> The UMIs were deduplicated using open source UMI-tools software package (version 1.1.2) [64]. Deduplicated mapped reads were counted on the gene level using FeatureCounts (version 2.0.1) [65] with options -M and–fraction (counting of multi-mapped reads with expression value as a fraction based on the number of genes assigned, ranging from 2–20 genes).\n",
    "\n",
    "You can see from the man page above that the `-M` flag allows for multi-mappers to be counted - these are reads that mapped to multiple different locations with equal quality scores. The `--fraction` argument tells the program how to account for multi-mapped reads:\n",
    "\n",
    "> When '-M' is specified, each reported alignment from a multi-mapping read (identified via 'NH' tag) will carry a fractional count of 1/x, instead of 1 (one), where x is the total number of alignments reported for the same read.\n",
    "\n",
    "So, if we have a read that mapped to two different genes, those two reads will count for 0.5 for each gene that it aligned to.\n",
    "\n",
    "## Dealing with duplicate reads\n",
    "\n",
    "So far, we have dealt with duplicate reads, even though we know from FASTQC that we had many duplicates. In the below example, over 60% of the reads were duplicates:\n",
    "\n",
    "<img src=\"assets/duplicates_2.png\" width=\"400\">\n",
    "\n",
    "Indeed, this was true of all samples:\n",
    "\n",
    "<img src=\"assets/duplicates.png\" width=\"400\">\n",
    "\n",
    "There are a few different reasons for why a sample would have many duplicate reads. The biggest reason is that, during library prep, there was a log amount of input RNA. This means that when the library is finished with the PCR enrichment steps, the library fragments are amplified so many times that many of the reads derived from duplicate fragments:\n",
    "\n",
    "<img src=\"assets/pcr.png\" width=\"400\">\n",
    "\n",
    "Many duplicate reads are a hallmark of RNA-seq experiments where the original tissue source was small, which resulted in low amounts of RNA being extracted. There are many different steps at which you can remove duplicates. Some people remove them from the FASTQ during trimming/filter, but my opinion is that is unnecessary and can potentially remove data that you might later be interested in. I think it's better to align the duplicates but mark them (rather than removing them) so that they aren't counted during the counting step. If you look at last week's [notebook on SAM/BAM QC](../7_alignment_qc/7_alignment_qc.ipynb), you'll see that the bit flag 0x400 represents a duplicate read. So, we can use a tool to update the read's flag if it is suspected to be a duplicate.\n",
    "\n",
    "To do this, we will first use [Picard Tools to mark the duplicate reads](https://gatk.broadinstitute.org/hc/en-us/articles/360037052812-MarkDuplicates-Picard); then we'll tell featureCounts to ignore anything marked as a duplicate (with the the `--ignoreDup` flag). This flag will analyze the FLAG field in the BAM and ignore any alignment that contains the duplicate bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘logs’: File exists\n",
      "mkdir: cannot create directory ‘dedup’: File exists\n",
      "[0.001s][warning][os,container] Duplicate cpuset controllers detected. Picking /sys/fs/cgroup/cpuset, skipping /dev/cpuset.\n",
      "16:34:42.477 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data/users/corwinbm5021/.conda/envs/biol343_20241029/share/picard-3.2.0-0/picard.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "[Tue Oct 29 16:34:42 CDT 2024] MarkDuplicates --INPUT ../6_alignment/alignment/star/Aligned.sortedByCoord.out.bam --OUTPUT dedup/star.bam --METRICS_FILE logs/star_duplicates --VALIDATION_STRINGENCY SILENT --MAX_SEQUENCES_FOR_DISK_READ_ENDS_MAP 50000 --MAX_FILE_HANDLES_FOR_READ_ENDS_MAP 8000 --SORTING_COLLECTION_SIZE_RATIO 0.25 --TAG_DUPLICATE_SET_MEMBERS false --REMOVE_SEQUENCING_DUPLICATES false --TAGGING_POLICY DontTag --CLEAR_DT true --DUPLEX_UMI false --FLOW_MODE false --FLOW_DUP_STRATEGY FLOW_QUALITY_SUM_STRATEGY --USE_END_IN_UNPAIRED_READS false --USE_UNPAIRED_CLIPPED_END false --UNPAIRED_END_UNCERTAINTY 0 --UNPAIRED_START_UNCERTAINTY 0 --FLOW_SKIP_FIRST_N_FLOWS 0 --FLOW_Q_IS_KNOWN_END false --FLOW_EFFECTIVE_QUALITY_THRESHOLD 15 --ADD_PG_TAG_TO_READS true --REMOVE_DUPLICATES false --ASSUME_SORTED false --DUPLICATE_SCORING_STRATEGY SUM_OF_BASE_QUALITIES --PROGRAM_RECORD_ID MarkDuplicates --PROGRAM_GROUP_NAME MarkDuplicates --READ_NAME_REGEX <optimized capture of last three ':' separated fields as numeric values> --OPTICAL_DUPLICATE_PIXEL_DISTANCE 100 --MAX_OPTICAL_DUPLICATE_SET_SIZE 300000 --VERBOSITY INFO --QUIET false --COMPRESSION_LEVEL 5 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false\n",
      "[Tue Oct 29 16:34:42 CDT 2024] Executing as corwinbm5021@cn44 on Linux 4.18.0-193.el8.x86_64 amd64; OpenJDK 64-Bit Server VM 17.0.3-internal+0-adhoc..src; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:3.2.0-1-g3948afb6b\n",
      "INFO\t2024-10-29 16:34:42\tMarkDuplicates\tStart of doWork freeMemory: 527357816; totalMemory: 536870912; maxMemory: 2147483648\n",
      "INFO\t2024-10-29 16:34:42\tMarkDuplicates\tReading input file and constructing read end information.\n",
      "INFO\t2024-10-29 16:34:42\tMarkDuplicates\tWill retain up to 7780737 data points before spilling to disk.\n",
      "WARNING\t2024-10-29 16:34:42\tAbstractOpticalDuplicateFinderCommandLineProgram\tA field field parsed out of a read name was expected to contain an integer and did not. Read name: SRR26691091.1928546. Cause: String 'SRR26691091.1928546' did not start with a parsable number.\n",
      "INFO\t2024-10-29 16:34:44\tMarkDuplicates\tRead     1,000,000 records.  Elapsed time: 00:00:01s.  Time for last 1,000,000:    1s.  Last read position: SM_V10_1:3,746,797\n",
      "INFO\t2024-10-29 16:34:44\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:34:46\tMarkDuplicates\tRead     2,000,000 records.  Elapsed time: 00:00:03s.  Time for last 1,000,000:    1s.  Last read position: SM_V10_1:5,453,645\n",
      "INFO\t2024-10-29 16:34:46\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:34:48\tMarkDuplicates\tRead     3,000,000 records.  Elapsed time: 00:00:05s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_1:11,168,477\n",
      "INFO\t2024-10-29 16:34:48\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:34:50\tMarkDuplicates\tRead     4,000,000 records.  Elapsed time: 00:00:07s.  Time for last 1,000,000:    1s.  Last read position: SM_V10_1:16,171,951\n",
      "INFO\t2024-10-29 16:34:50\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:34:51\tMarkDuplicates\tRead     5,000,000 records.  Elapsed time: 00:00:08s.  Time for last 1,000,000:    1s.  Last read position: SM_V10_1:16,328,107\n",
      "INFO\t2024-10-29 16:34:51\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:34:53\tMarkDuplicates\tRead     6,000,000 records.  Elapsed time: 00:00:11s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_1:20,833,138\n",
      "INFO\t2024-10-29 16:34:53\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:34:56\tMarkDuplicates\tRead     7,000,000 records.  Elapsed time: 00:00:13s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_1:26,493,213\n",
      "INFO\t2024-10-29 16:34:56\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:34:58\tMarkDuplicates\tRead     8,000,000 records.  Elapsed time: 00:00:15s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_1:33,865,398\n",
      "INFO\t2024-10-29 16:34:58\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:35:00\tMarkDuplicates\tRead     9,000,000 records.  Elapsed time: 00:00:18s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_1:37,948,963\n",
      "INFO\t2024-10-29 16:35:00\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:35:02\tMarkDuplicates\tRead    10,000,000 records.  Elapsed time: 00:00:19s.  Time for last 1,000,000:    1s.  Last read position: SM_V10_1:40,758,032\n",
      "INFO\t2024-10-29 16:35:02\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:35:04\tMarkDuplicates\tRead    11,000,000 records.  Elapsed time: 00:00:21s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_1:44,529,154\n",
      "INFO\t2024-10-29 16:35:04\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:35:07\tMarkDuplicates\tRead    12,000,000 records.  Elapsed time: 00:00:24s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_1:49,824,659\n",
      "INFO\t2024-10-29 16:35:07\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:35:12\tMarkDuplicates\tRead    13,000,000 records.  Elapsed time: 00:00:29s.  Time for last 1,000,000:    5s.  Last read position: SM_V10_1:57,513,167\n",
      "INFO\t2024-10-29 16:35:12\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:35:14\tMarkDuplicates\tRead    14,000,000 records.  Elapsed time: 00:00:31s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_1:62,576,919\n",
      "INFO\t2024-10-29 16:35:14\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:35:15\tMarkDuplicates\tRead    15,000,000 records.  Elapsed time: 00:00:33s.  Time for last 1,000,000:    1s.  Last read position: SM_V10_1:62,613,119\n",
      "INFO\t2024-10-29 16:35:15\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:35:17\tMarkDuplicates\tRead    16,000,000 records.  Elapsed time: 00:00:34s.  Time for last 1,000,000:    1s.  Last read position: SM_V10_1:64,662,030\n",
      "INFO\t2024-10-29 16:35:17\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:35:19\tMarkDuplicates\tRead    17,000,000 records.  Elapsed time: 00:00:36s.  Time for last 1,000,000:    1s.  Last read position: SM_V10_1:64,905,108\n",
      "INFO\t2024-10-29 16:35:19\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:35:22\tMarkDuplicates\tRead    18,000,000 records.  Elapsed time: 00:00:39s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_1:69,446,755\n",
      "INFO\t2024-10-29 16:35:22\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:35:24\tMarkDuplicates\tRead    19,000,000 records.  Elapsed time: 00:00:42s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_1:75,012,105\n",
      "INFO\t2024-10-29 16:35:24\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:35:27\tMarkDuplicates\tRead    20,000,000 records.  Elapsed time: 00:00:44s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_1:79,229,428\n",
      "INFO\t2024-10-29 16:35:27\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:35:30\tMarkDuplicates\tRead    21,000,000 records.  Elapsed time: 00:00:47s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_1:87,515,445\n",
      "INFO\t2024-10-29 16:35:30\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:35:32\tMarkDuplicates\tRead    22,000,000 records.  Elapsed time: 00:00:49s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_Z:8,925,146\n",
      "INFO\t2024-10-29 16:35:32\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:35:35\tMarkDuplicates\tRead    23,000,000 records.  Elapsed time: 00:00:52s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_Z:17,649,899\n",
      "INFO\t2024-10-29 16:35:35\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:35:40\tMarkDuplicates\tRead    24,000,000 records.  Elapsed time: 00:00:57s.  Time for last 1,000,000:    4s.  Last read position: SM_V10_Z:25,628,337\n",
      "INFO\t2024-10-29 16:35:40\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:35:42\tMarkDuplicates\tRead    25,000,000 records.  Elapsed time: 00:01:00s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_Z:29,638,232\n",
      "INFO\t2024-10-29 16:35:42\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:35:45\tMarkDuplicates\tRead    26,000,000 records.  Elapsed time: 00:01:02s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_Z:35,708,652\n",
      "INFO\t2024-10-29 16:35:45\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:35:48\tMarkDuplicates\tRead    27,000,000 records.  Elapsed time: 00:01:05s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_Z:41,348,707\n",
      "INFO\t2024-10-29 16:35:48\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:35:51\tMarkDuplicates\tRead    28,000,000 records.  Elapsed time: 00:01:08s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_Z:47,207,033\n",
      "INFO\t2024-10-29 16:35:51\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:35:53\tMarkDuplicates\tRead    29,000,000 records.  Elapsed time: 00:01:10s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_Z:56,589,093\n",
      "INFO\t2024-10-29 16:35:53\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:35:56\tMarkDuplicates\tRead    30,000,000 records.  Elapsed time: 00:01:13s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_Z:64,470,513\n",
      "INFO\t2024-10-29 16:35:56\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:35:58\tMarkDuplicates\tRead    31,000,000 records.  Elapsed time: 00:01:15s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_Z:72,662,387\n",
      "INFO\t2024-10-29 16:35:58\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:36:01\tMarkDuplicates\tRead    32,000,000 records.  Elapsed time: 00:01:18s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_Z:77,213,949\n",
      "INFO\t2024-10-29 16:36:01\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:36:05\tMarkDuplicates\tRead    33,000,000 records.  Elapsed time: 00:01:22s.  Time for last 1,000,000:    4s.  Last read position: SM_V10_Z:83,385,516\n",
      "INFO\t2024-10-29 16:36:05\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:36:08\tMarkDuplicates\tRead    34,000,000 records.  Elapsed time: 00:01:25s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_3:2,562,011\n",
      "INFO\t2024-10-29 16:36:08\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:36:10\tMarkDuplicates\tRead    35,000,000 records.  Elapsed time: 00:01:27s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_3:8,992,265\n",
      "INFO\t2024-10-29 16:36:10\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:36:13\tMarkDuplicates\tRead    36,000,000 records.  Elapsed time: 00:01:30s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_3:17,225,983\n",
      "INFO\t2024-10-29 16:36:13\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:36:16\tMarkDuplicates\tRead    37,000,000 records.  Elapsed time: 00:01:33s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_3:24,418,010\n",
      "INFO\t2024-10-29 16:36:16\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:36:18\tMarkDuplicates\tRead    38,000,000 records.  Elapsed time: 00:01:35s.  Time for last 1,000,000:    1s.  Last read position: SM_V10_3:27,291,911\n",
      "INFO\t2024-10-29 16:36:18\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:36:19\tMarkDuplicates\tRead    39,000,000 records.  Elapsed time: 00:01:37s.  Time for last 1,000,000:    1s.  Last read position: SM_V10_3:29,628,086\n",
      "INFO\t2024-10-29 16:36:19\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:36:22\tMarkDuplicates\tRead    40,000,000 records.  Elapsed time: 00:01:39s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_3:35,973,543\n",
      "INFO\t2024-10-29 16:36:22\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:36:25\tMarkDuplicates\tRead    41,000,000 records.  Elapsed time: 00:01:42s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_3:45,144,918\n",
      "INFO\t2024-10-29 16:36:25\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:36:26\tMarkDuplicates\tRead    42,000,000 records.  Elapsed time: 00:01:43s.  Time for last 1,000,000:    1s.  Last read position: SM_V10_3:46,097,981\n",
      "INFO\t2024-10-29 16:36:26\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:36:28\tMarkDuplicates\tRead    43,000,000 records.  Elapsed time: 00:01:45s.  Time for last 1,000,000:    1s.  Last read position: SM_V10_3:46,204,814\n",
      "INFO\t2024-10-29 16:36:28\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:36:29\tMarkDuplicates\tRead    44,000,000 records.  Elapsed time: 00:01:46s.  Time for last 1,000,000:    1s.  Last read position: SM_V10_3:47,577,899\n",
      "INFO\t2024-10-29 16:36:29\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:36:32\tMarkDuplicates\tRead    45,000,000 records.  Elapsed time: 00:01:49s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_4:5,310,845\n",
      "INFO\t2024-10-29 16:36:32\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:36:36\tMarkDuplicates\tRead    46,000,000 records.  Elapsed time: 00:01:53s.  Time for last 1,000,000:    4s.  Last read position: SM_V10_4:12,387,121\n",
      "INFO\t2024-10-29 16:36:36\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:36:39\tMarkDuplicates\tRead    47,000,000 records.  Elapsed time: 00:01:56s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_4:21,896,740\n",
      "INFO\t2024-10-29 16:36:39\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:36:42\tMarkDuplicates\tRead    48,000,000 records.  Elapsed time: 00:01:59s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_4:30,212,741\n",
      "INFO\t2024-10-29 16:36:42\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:36:44\tMarkDuplicates\tRead    49,000,000 records.  Elapsed time: 00:02:02s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_4:35,742,922\n",
      "INFO\t2024-10-29 16:36:44\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:36:47\tMarkDuplicates\tRead    50,000,000 records.  Elapsed time: 00:02:04s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_4:41,242,493\n",
      "INFO\t2024-10-29 16:36:47\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:36:49\tMarkDuplicates\tRead    51,000,000 records.  Elapsed time: 00:02:07s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_4:46,242,759\n",
      "INFO\t2024-10-29 16:36:49\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:36:52\tMarkDuplicates\tRead    52,000,000 records.  Elapsed time: 00:02:09s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_2:3,722,084\n",
      "INFO\t2024-10-29 16:36:52\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:36:54\tMarkDuplicates\tRead    53,000,000 records.  Elapsed time: 00:02:12s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_2:12,697,569\n",
      "INFO\t2024-10-29 16:36:54\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:36:57\tMarkDuplicates\tRead    54,000,000 records.  Elapsed time: 00:02:14s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_2:21,860,729\n",
      "INFO\t2024-10-29 16:36:57\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:37:02\tMarkDuplicates\tRead    55,000,000 records.  Elapsed time: 00:02:19s.  Time for last 1,000,000:    4s.  Last read position: SM_V10_2:31,016,783\n",
      "INFO\t2024-10-29 16:37:02\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:37:04\tMarkDuplicates\tRead    56,000,000 records.  Elapsed time: 00:02:21s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_2:38,011,537\n",
      "INFO\t2024-10-29 16:37:04\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:37:05\tMarkDuplicates\tRead    57,000,000 records.  Elapsed time: 00:02:22s.  Time for last 1,000,000:    1s.  Last read position: SM_V10_2:38,090,232\n",
      "INFO\t2024-10-29 16:37:05\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:37:07\tMarkDuplicates\tRead    58,000,000 records.  Elapsed time: 00:02:24s.  Time for last 1,000,000:    1s.  Last read position: SM_V10_2:38,169,541\n",
      "INFO\t2024-10-29 16:37:07\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:37:08\tMarkDuplicates\tRead    59,000,000 records.  Elapsed time: 00:02:26s.  Time for last 1,000,000:    1s.  Last read position: SM_V10_2:38,246,680\n",
      "INFO\t2024-10-29 16:37:08\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:37:10\tMarkDuplicates\tRead    60,000,000 records.  Elapsed time: 00:02:27s.  Time for last 1,000,000:    1s.  Last read position: SM_V10_2:38,310,818\n",
      "INFO\t2024-10-29 16:37:10\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:37:12\tMarkDuplicates\tRead    61,000,000 records.  Elapsed time: 00:02:29s.  Time for last 1,000,000:    1s.  Last read position: SM_V10_2:38,333,718\n",
      "INFO\t2024-10-29 16:37:12\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:37:13\tMarkDuplicates\tRead    62,000,000 records.  Elapsed time: 00:02:30s.  Time for last 1,000,000:    1s.  Last read position: SM_V10_2:38,350,407\n",
      "INFO\t2024-10-29 16:37:13\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:37:15\tMarkDuplicates\tRead    63,000,000 records.  Elapsed time: 00:02:32s.  Time for last 1,000,000:    1s.  Last read position: SM_V10_2:39,689,185\n",
      "INFO\t2024-10-29 16:37:15\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:37:17\tMarkDuplicates\tRead    64,000,000 records.  Elapsed time: 00:02:34s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_2:41,829,927\n",
      "INFO\t2024-10-29 16:37:17\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:37:19\tMarkDuplicates\tRead    65,000,000 records.  Elapsed time: 00:02:37s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_2:45,597,869\n",
      "INFO\t2024-10-29 16:37:19\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:37:22\tMarkDuplicates\tRead    66,000,000 records.  Elapsed time: 00:02:39s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_6:7,721,719\n",
      "INFO\t2024-10-29 16:37:22\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:37:24\tMarkDuplicates\tRead    67,000,000 records.  Elapsed time: 00:02:41s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_6:11,006,658\n",
      "INFO\t2024-10-29 16:37:24\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:37:27\tMarkDuplicates\tRead    68,000,000 records.  Elapsed time: 00:02:44s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_6:17,282,577\n",
      "INFO\t2024-10-29 16:37:27\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:37:29\tMarkDuplicates\tRead    69,000,000 records.  Elapsed time: 00:02:46s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_6:19,910,437\n",
      "INFO\t2024-10-29 16:37:29\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:37:31\tMarkDuplicates\tRead    70,000,000 records.  Elapsed time: 00:02:48s.  Time for last 1,000,000:    1s.  Last read position: SM_V10_6:22,557,390\n",
      "INFO\t2024-10-29 16:37:31\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:37:35\tMarkDuplicates\tRead    71,000,000 records.  Elapsed time: 00:02:52s.  Time for last 1,000,000:    3s.  Last read position: SM_V10_5:4,149,929\n",
      "INFO\t2024-10-29 16:37:35\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:37:37\tMarkDuplicates\tRead    72,000,000 records.  Elapsed time: 00:02:54s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_5:9,189,159\n",
      "INFO\t2024-10-29 16:37:37\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:37:40\tMarkDuplicates\tRead    73,000,000 records.  Elapsed time: 00:02:57s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_5:16,485,674\n",
      "INFO\t2024-10-29 16:37:40\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:37:42\tMarkDuplicates\tRead    74,000,000 records.  Elapsed time: 00:02:59s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_5:20,083,673\n",
      "INFO\t2024-10-29 16:37:42\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:37:45\tMarkDuplicates\tRead    75,000,000 records.  Elapsed time: 00:03:02s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_7:4,598,993\n",
      "INFO\t2024-10-29 16:37:45\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:37:48\tMarkDuplicates\tRead    76,000,000 records.  Elapsed time: 00:03:05s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_7:14,576,972\n",
      "INFO\t2024-10-29 16:37:48\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:37:50\tMarkDuplicates\tRead    77,000,000 records.  Elapsed time: 00:03:07s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_7:18,153,216\n",
      "INFO\t2024-10-29 16:37:50\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:37:52\tMarkDuplicates\tRead    78,000,000 records.  Elapsed time: 00:03:09s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_MITO:184\n",
      "INFO\t2024-10-29 16:37:52\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:37:55\tMarkDuplicates\tRead    79,000,000 records.  Elapsed time: 00:03:12s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_MITO:285\n",
      "INFO\t2024-10-29 16:37:55\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:37:57\tMarkDuplicates\tRead    80,000,000 records.  Elapsed time: 00:03:14s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_MITO:547\n",
      "INFO\t2024-10-29 16:37:57\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:37:59\tMarkDuplicates\tRead    81,000,000 records.  Elapsed time: 00:03:16s.  Time for last 1,000,000:    1s.  Last read position: SM_V10_MITO:790\n",
      "INFO\t2024-10-29 16:37:59\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:38:01\tMarkDuplicates\tRead    82,000,000 records.  Elapsed time: 00:03:18s.  Time for last 1,000,000:    1s.  Last read position: SM_V10_MITO:994\n",
      "INFO\t2024-10-29 16:38:01\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:38:04\tMarkDuplicates\tRead    83,000,000 records.  Elapsed time: 00:03:22s.  Time for last 1,000,000:    3s.  Last read position: SM_V10_MITO:1,272\n",
      "INFO\t2024-10-29 16:38:04\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:38:07\tMarkDuplicates\tRead    84,000,000 records.  Elapsed time: 00:03:24s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_MITO:2,092\n",
      "INFO\t2024-10-29 16:38:07\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:38:09\tMarkDuplicates\tRead    85,000,000 records.  Elapsed time: 00:03:26s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_MITO:2,278\n",
      "INFO\t2024-10-29 16:38:09\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:38:12\tMarkDuplicates\tRead    86,000,000 records.  Elapsed time: 00:03:29s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_MITO:2,361\n",
      "INFO\t2024-10-29 16:38:12\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:38:14\tMarkDuplicates\tRead    87,000,000 records.  Elapsed time: 00:03:31s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_MITO:2,434\n",
      "INFO\t2024-10-29 16:38:14\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:38:16\tMarkDuplicates\tRead    88,000,000 records.  Elapsed time: 00:03:33s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_MITO:2,641\n",
      "INFO\t2024-10-29 16:38:16\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:38:18\tMarkDuplicates\tRead    89,000,000 records.  Elapsed time: 00:03:35s.  Time for last 1,000,000:    1s.  Last read position: SM_V10_MITO:2,837\n",
      "INFO\t2024-10-29 16:38:18\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:38:21\tMarkDuplicates\tRead    90,000,000 records.  Elapsed time: 00:03:38s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_MITO:3,498\n",
      "INFO\t2024-10-29 16:38:21\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:38:23\tMarkDuplicates\tRead    91,000,000 records.  Elapsed time: 00:03:40s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_MITO:3,544\n",
      "INFO\t2024-10-29 16:38:23\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:38:26\tMarkDuplicates\tRead    92,000,000 records.  Elapsed time: 00:03:43s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_MITO:3,937\n",
      "INFO\t2024-10-29 16:38:26\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:38:28\tMarkDuplicates\tRead    93,000,000 records.  Elapsed time: 00:03:45s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_MITO:4,337\n",
      "INFO\t2024-10-29 16:38:28\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:38:32\tMarkDuplicates\tRead    94,000,000 records.  Elapsed time: 00:03:50s.  Time for last 1,000,000:    4s.  Last read position: SM_V10_MITO:5,242\n",
      "INFO\t2024-10-29 16:38:32\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:38:35\tMarkDuplicates\tRead    95,000,000 records.  Elapsed time: 00:03:52s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_MITO:5,420\n",
      "INFO\t2024-10-29 16:38:35\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:38:37\tMarkDuplicates\tRead    96,000,000 records.  Elapsed time: 00:03:55s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_MITO:6,180\n",
      "INFO\t2024-10-29 16:38:37\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:38:40\tMarkDuplicates\tRead    97,000,000 records.  Elapsed time: 00:03:57s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_MITO:7,120\n",
      "INFO\t2024-10-29 16:38:40\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:38:42\tMarkDuplicates\tRead    98,000,000 records.  Elapsed time: 00:04:00s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_MITO:7,274\n",
      "INFO\t2024-10-29 16:38:42\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:38:45\tMarkDuplicates\tRead    99,000,000 records.  Elapsed time: 00:04:02s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_MITO:7,332\n",
      "INFO\t2024-10-29 16:38:45\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:38:47\tMarkDuplicates\tRead   100,000,000 records.  Elapsed time: 00:04:04s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_MITO:7,357\n",
      "INFO\t2024-10-29 16:38:47\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:38:49\tMarkDuplicates\tRead   101,000,000 records.  Elapsed time: 00:04:06s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_MITO:7,804\n",
      "INFO\t2024-10-29 16:38:49\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:38:52\tMarkDuplicates\tRead   102,000,000 records.  Elapsed time: 00:04:09s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_MITO:9,144\n",
      "INFO\t2024-10-29 16:38:52\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:38:54\tMarkDuplicates\tRead   103,000,000 records.  Elapsed time: 00:04:11s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_MITO:9,262\n",
      "INFO\t2024-10-29 16:38:54\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:38:55\tMarkDuplicates\tRead   104,000,000 records.  Elapsed time: 00:04:13s.  Time for last 1,000,000:    1s.  Last read position: SM_V10_MITO:9,307\n",
      "INFO\t2024-10-29 16:38:55\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:38:58\tMarkDuplicates\tRead   105,000,000 records.  Elapsed time: 00:04:15s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_MITO:9,940\n",
      "INFO\t2024-10-29 16:38:58\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:39:02\tMarkDuplicates\tRead   106,000,000 records.  Elapsed time: 00:04:19s.  Time for last 1,000,000:    4s.  Last read position: SM_V10_MITO:9,971\n",
      "INFO\t2024-10-29 16:39:02\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:39:05\tMarkDuplicates\tRead   107,000,000 records.  Elapsed time: 00:04:22s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_MITO:10,032\n",
      "INFO\t2024-10-29 16:39:05\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:39:07\tMarkDuplicates\tRead   108,000,000 records.  Elapsed time: 00:04:24s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_MITO:10,869\n",
      "INFO\t2024-10-29 16:39:07\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:39:10\tMarkDuplicates\tRead   109,000,000 records.  Elapsed time: 00:04:27s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_MITO:12,505\n",
      "INFO\t2024-10-29 16:39:10\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:39:12\tMarkDuplicates\tRead   110,000,000 records.  Elapsed time: 00:04:29s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_MITO:12,757\n",
      "INFO\t2024-10-29 16:39:12\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:39:15\tMarkDuplicates\tRead   111,000,000 records.  Elapsed time: 00:04:32s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_MITO:12,785\n",
      "INFO\t2024-10-29 16:39:15\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:39:17\tMarkDuplicates\tRead   112,000,000 records.  Elapsed time: 00:04:35s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_MITO:12,790\n",
      "INFO\t2024-10-29 16:39:17\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:39:20\tMarkDuplicates\tRead   113,000,000 records.  Elapsed time: 00:04:37s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_MITO:12,826\n",
      "INFO\t2024-10-29 16:39:20\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:39:22\tMarkDuplicates\tRead   114,000,000 records.  Elapsed time: 00:04:39s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_MITO:13,286\n",
      "INFO\t2024-10-29 16:39:22\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:39:27\tMarkDuplicates\tRead   115,000,000 records.  Elapsed time: 00:04:44s.  Time for last 1,000,000:    4s.  Last read position: SM_V10_MITO:13,940\n",
      "INFO\t2024-10-29 16:39:27\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:39:28\tMarkDuplicates\tRead   116,000,000 records.  Elapsed time: 00:04:45s.  Time for last 1,000,000:    1s.  Last read position: SM_V10_MITO:14,600\n",
      "INFO\t2024-10-29 16:39:28\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:39:31\tMarkDuplicates\tRead   117,000,000 records.  Elapsed time: 00:04:48s.  Time for last 1,000,000:    2s.  Last read position: SM_V10_MITO:15,266\n",
      "INFO\t2024-10-29 16:39:31\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:39:32\tMarkDuplicates\tRead   118,000,000 records.  Elapsed time: 00:04:49s.  Time for last 1,000,000:    1s.  Last read position: SM_V10_MITO:16,012\n",
      "INFO\t2024-10-29 16:39:32\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:39:33\tMarkDuplicates\tRead   119,000,000 records.  Elapsed time: 00:04:50s.  Time for last 1,000,000:    0s.  Last read position: SM_V10_MITO:16,590\n",
      "INFO\t2024-10-29 16:39:33\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:39:34\tMarkDuplicates\tRead   120,000,000 records.  Elapsed time: 00:04:51s.  Time for last 1,000,000:    0s.  Last read position: SM_V10_MITO:17,123\n",
      "INFO\t2024-10-29 16:39:34\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:39:35\tMarkDuplicates\tRead   121,000,000 records.  Elapsed time: 00:04:52s.  Time for last 1,000,000:    0s.  Last read position: SM_V10_MITO:17,924\n",
      "INFO\t2024-10-29 16:39:35\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:39:36\tMarkDuplicates\tRead   122,000,000 records.  Elapsed time: 00:04:53s.  Time for last 1,000,000:    0s.  Last read position: SM_V10_MITO:19,159\n",
      "INFO\t2024-10-29 16:39:36\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:39:37\tMarkDuplicates\tRead   123,000,000 records.  Elapsed time: 00:04:54s.  Time for last 1,000,000:    0s.  Last read position: SM_V10_MITO:19,643\n",
      "INFO\t2024-10-29 16:39:37\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:39:38\tMarkDuplicates\tRead   124,000,000 records.  Elapsed time: 00:04:55s.  Time for last 1,000,000:    0s.  Last read position: SM_V10_MITO:20,389\n",
      "INFO\t2024-10-29 16:39:38\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:39:39\tMarkDuplicates\tRead   125,000,000 records.  Elapsed time: 00:04:57s.  Time for last 1,000,000:    1s.  Last read position: SM_V10_MITO:22,746\n",
      "INFO\t2024-10-29 16:39:39\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:39:40\tMarkDuplicates\tRead   126,000,000 records.  Elapsed time: 00:04:57s.  Time for last 1,000,000:    0s.  Last read position: SM_V10_MITO:23,349\n",
      "INFO\t2024-10-29 16:39:40\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:39:41\tMarkDuplicates\tRead   127,000,000 records.  Elapsed time: 00:04:58s.  Time for last 1,000,000:    0s.  Last read position: SM_V10_MITO:25,722\n",
      "INFO\t2024-10-29 16:39:41\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:39:42\tMarkDuplicates\tRead   128,000,000 records.  Elapsed time: 00:04:59s.  Time for last 1,000,000:    1s.  Last read position: SM_V10_MITO:26,467\n",
      "INFO\t2024-10-29 16:39:42\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-10-29 16:39:43\tMarkDuplicates\tRead 128542194 records. 0 pairs never matched.\n",
      "INFO\t2024-10-29 16:39:43\tMarkDuplicates\tAfter buildSortedReadEndLists freeMemory: 495156880; totalMemory: 536870912; maxMemory: 2147483648\n",
      "INFO\t2024-10-29 16:39:43\tMarkDuplicates\tWill retain up to 67108864 duplicate indices before spilling to disk.\n",
      "INFO\t2024-10-29 16:39:43\tMarkDuplicates\tTraversing read pair information and detecting duplicates.\n",
      "INFO\t2024-10-29 16:39:43\tMarkDuplicates\tTraversing fragment information and detecting duplicates.\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "%mkdir logs\n",
    "%mkdir dedup\n",
    "\n",
    "!picard MarkDuplicates -I ../6_alignment/alignment/star/Aligned.sortedByCoord.out.bam -M logs/star_duplicates -O dedup/star.bam --VALIDATION_STRINGENCY SILENT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***20 minutes to complete***\n",
    "\n",
    "Finally, we are also going to use the stranded argument because the QuantSeq FWD 3’mRNA Library Prep Kit is a stranded kit. That is, the library was created such that we can be 100% confident that each fragment that we sequenced represents the same sequences as the template mRNA. Here's the final `featureCounts` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       \u001b[44;37m ========== \u001b[0m\u001b[36m    _____ _    _ ____  _____  ______          _____  \n",
      "       \u001b[44;37m =====      \u001b[0m\u001b[36m   / ____| |  | |  _ \\|  __ \\|  ____|   /\\   |  __ \\ \n",
      "       \u001b[44;37m   =====    \u001b[0m\u001b[36m  | (___ | |  | | |_) | |__) | |__     /  \\  | |  | |\n",
      "       \u001b[44;37m     ====   \u001b[0m\u001b[36m   \\___ \\| |  | |  _ <|  _  /|  __|   / /\\ \\ | |  | |\n",
      "       \u001b[44;37m       ==== \u001b[0m\u001b[36m   ____) | |__| | |_) | | \\ \\| |____ / ____ \\| |__| |\n",
      "       \u001b[44;37m ========== \u001b[0m\u001b[36m  |_____/ \\____/|____/|_|  \\_\\______/_/    \\_\\_____/\u001b[0m\n",
      "\t  v2.0.6\n",
      "\n",
      "//==========================\u001b[36m featureCounts setting \u001b[0m===========================\\\\\n",
      "||  \u001b[0m                                                                          ||\n",
      "||             Input files : \u001b[36m1 BAM file  \u001b[0m \u001b[0m                                    ||\n",
      "||  \u001b[0m                                                                          ||\n",
      "||                           \u001b[36mstar.bam\u001b[0m \u001b[0m                                        ||\n",
      "||  \u001b[0m                                                                          ||\n",
      "||             Output file : \u001b[36mstar_counts.tsv\u001b[0m \u001b[0m                                 ||\n",
      "||                 Summary : \u001b[36mstar_counts.tsv.summary\u001b[0m \u001b[0m                         ||\n",
      "||              Paired-end : \u001b[36mno\u001b[0m \u001b[0m                                              ||\n",
      "||        Count read pairs : \u001b[36mno\u001b[0m \u001b[0m                                              ||\n",
      "||              Annotation : \u001b[36mannotations.gtf (GTF)\u001b[0m \u001b[0m                           ||\n",
      "||      Dir for temp files : \u001b[36m./\u001b[0m \u001b[0m                                              ||\n",
      "||  \u001b[0m                                                                          ||\n",
      "||                 Threads : \u001b[36m32\u001b[0m \u001b[0m                                              ||\n",
      "||                   Level : \u001b[36mmeta-feature level\u001b[0m \u001b[0m                              ||\n",
      "||      Multimapping reads : \u001b[36mcounted (fractional)\u001b[0m \u001b[0m                            ||\n",
      "|| Multi-overlapping reads : \u001b[36mnot counted\u001b[0m \u001b[0m                                     ||\n",
      "||   Min overlapping bases : \u001b[36m1\u001b[0m \u001b[0m                                               ||\n",
      "||        Duplicated Reads : \u001b[36mignored\u001b[0m \u001b[0m                                         ||\n",
      "||  \u001b[0m                                                                          ||\n",
      "\\\\============================================================================//\n",
      "\n",
      "//=================================\u001b[36m Running \u001b[0m==================================\\\\\n",
      "||  \u001b[0m                                                                          ||\n",
      "|| Load annotation file annotations.gtf \u001b[0m... \u001b[0m                                  ||\n",
      "||    Features : \u001b[36m88812\u001b[0m \u001b[0m                                                       ||\n",
      "||    Meta-features : \u001b[36m9920\u001b[0m \u001b[0m                                                   ||\n",
      "||    Chromosomes/contigs : \u001b[36m10\u001b[0m \u001b[0m                                               ||\n",
      "||  \u001b[0m                                                                          ||\n",
      "|| Process BAM file star.bam... \u001b[0m                                              ||\n",
      "||    Strand specific : \u001b[36mstranded\u001b[0m \u001b[0m                                             ||\n",
      "||    Single-end reads are included. \u001b[0m                                         ||\n",
      "||    Total read groups : \u001b[36m12\u001b[0m \u001b[0m                                                 ||\n",
      "||    Total alignments : \u001b[36m171342056\u001b[0m \u001b[0m                                           ||\n",
      "||    Successfully assigned alignments : \u001b[36m19944959 (11.6%)\u001b[0m \u001b[0m                    ||\n",
      "||    Running time : \u001b[36m0.08 minutes\u001b[0m \u001b[0m                                            ||\n",
      "||  \u001b[0m                                                                          ||\n",
      "|| Write the final count table. \u001b[0m                                              ||\n",
      "|| Write the read assignment summary. \u001b[0m                                        ||\n",
      "||  \u001b[0m                                                                          ||\n",
      "|| Summary of counting results can be found in file \"star_counts.tsv.summary \u001b[0m ||\n",
      "|| \" \u001b[0m                                                                         ||\n",
      "||  \u001b[0m                                                                          ||\n",
      "\\\\============================================================================//\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!featureCounts -T 32 \\\n",
    "    /data/classes/2024/fall/biol343/course_files/dedup/star.bam \\\n",
    "    -T 32 \\\n",
    "    --byReadGroup \\\n",
    "    -s 1 \\\n",
    "    --ignoreDup \\\n",
    "    -M \\\n",
    "    --fraction \\\n",
    "    -a ../2_genome_exploration/genome/annotations.gtf \\\n",
    "    -o star_counts.tsv \\\n",
    "    --verbose"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now are finally at a point in the analysis in which we can compare our results with the results published in the Winners vs. Losers paper. One of their most prominent results was showing the immunomodulatory gene Smp_245390 was more highly expressed in mature liver eggs than mature intestinal eggs:\n",
    "\n",
    "<img src=\"assets/fig4d.png\" width=\"400\">\n",
    "\n",
    "The paper also included their own counting results in [S2 Table](https://journals.plos.org/plospathogens/article/file?type=supplementary&id=10.1371/journal.ppat.1012268.s002). Here are their results and our results compared:\n",
    "\n",
    "| Analysis | INT_im1 | INT_im2 | INT_im3 | INT_ma1 | INT_ma2 | INT_ma3 | LIV_im1 | LIV_im2 | LIV_im3 | LIV_ma1 | LIV_ma2 | LIV_ma3 |\n",
    "|----------|---------|---------|---------|---------|---------|---------|---------|---------|---------|---------|---------|---------|\n",
    "| Theirs   | 2.84\t | 2.35\t   | 20.46 \t | 29.45   | 49.03   | 16.17   | 258.46  | 11.50   | 11.67   | 227.95  | 94.20   | 63.37   |\n",
    "| Ours     | 0.5     | 1       | 12.3    | 8.67    | 8       | 1       | 218.48  | 2.38    | 4       | 269.16  | 76.61   | 36.19   |\n",
    "\n",
    "Looks pretty good! Our counts are lower than theirs across the board (other than LIV_ma1), but the main patterns hold true. Based on these numbers, it will look like our analysis is likely to reproduce the main finding from the paper - that Smp_245390 is significantly more highly exprssed in mature liver eggs than mature intestine eggs.\n",
    "\n",
    "Let's now do all of that again, but with the HISAT alignment..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       \u001b[44;37m ========== \u001b[0m\u001b[36m    _____ _    _ ____  _____  ______          _____  \n",
      "       \u001b[44;37m =====      \u001b[0m\u001b[36m   / ____| |  | |  _ \\|  __ \\|  ____|   /\\   |  __ \\ \n",
      "       \u001b[44;37m   =====    \u001b[0m\u001b[36m  | (___ | |  | | |_) | |__) | |__     /  \\  | |  | |\n",
      "       \u001b[44;37m     ====   \u001b[0m\u001b[36m   \\___ \\| |  | |  _ <|  _  /|  __|   / /\\ \\ | |  | |\n",
      "       \u001b[44;37m       ==== \u001b[0m\u001b[36m   ____) | |__| | |_) | | \\ \\| |____ / ____ \\| |__| |\n",
      "       \u001b[44;37m ========== \u001b[0m\u001b[36m  |_____/ \\____/|____/|_|  \\_\\______/_/    \\_\\_____/\u001b[0m\n",
      "\t  v2.0.6\n",
      "\n",
      "//==========================\u001b[36m featureCounts setting \u001b[0m===========================\\\\\n",
      "||  \u001b[0m                                                                          ||\n",
      "||             Input files : \u001b[36m1 BAM file  \u001b[0m \u001b[0m                                    ||\n",
      "||  \u001b[0m                                                                          ||\n",
      "||                           \u001b[36mhisat.bam\u001b[0m \u001b[0m                                       ||\n",
      "||  \u001b[0m                                                                          ||\n",
      "||             Output file : \u001b[36mhisat_counts.tsv\u001b[0m \u001b[0m                                ||\n",
      "||                 Summary : \u001b[36mhisat_counts.tsv.summary\u001b[0m \u001b[0m                        ||\n",
      "||              Paired-end : \u001b[36mno\u001b[0m \u001b[0m                                              ||\n",
      "||        Count read pairs : \u001b[36mno\u001b[0m \u001b[0m                                              ||\n",
      "||              Annotation : \u001b[36mannotations.gtf (GTF)\u001b[0m \u001b[0m                           ||\n",
      "||      Dir for temp files : \u001b[36m./\u001b[0m \u001b[0m                                              ||\n",
      "||  \u001b[0m                                                                          ||\n",
      "||                 Threads : \u001b[36m32\u001b[0m \u001b[0m                                              ||\n",
      "||                   Level : \u001b[36mmeta-feature level\u001b[0m \u001b[0m                              ||\n",
      "||      Multimapping reads : \u001b[36mcounted (fractional)\u001b[0m \u001b[0m                            ||\n",
      "|| Multi-overlapping reads : \u001b[36mnot counted\u001b[0m \u001b[0m                                     ||\n",
      "||   Min overlapping bases : \u001b[36m1\u001b[0m \u001b[0m                                               ||\n",
      "||        Duplicated Reads : \u001b[36mignored\u001b[0m \u001b[0m                                         ||\n",
      "||  \u001b[0m                                                                          ||\n",
      "\\\\============================================================================//\n",
      "\n",
      "//=================================\u001b[36m Running \u001b[0m==================================\\\\\n",
      "||  \u001b[0m                                                                          ||\n",
      "|| Load annotation file annotations.gtf \u001b[0m... \u001b[0m                                  ||\n",
      "||    Features : \u001b[36m88812\u001b[0m \u001b[0m                                                       ||\n",
      "||    Meta-features : \u001b[36m9920\u001b[0m \u001b[0m                                                   ||\n",
      "||    Chromosomes/contigs : \u001b[36m10\u001b[0m \u001b[0m                                               ||\n",
      "||  \u001b[0m                                                                          ||\n",
      "|| Process BAM file hisat.bam... \u001b[0m                                             ||\n",
      "||    Strand specific : \u001b[36mstranded\u001b[0m \u001b[0m                                             ||\n",
      "||    Single-end reads are included. \u001b[0m                                         ||\n",
      "||    Total read groups : \u001b[36m12\u001b[0m \u001b[0m                                                 ||\n",
      "||    Total alignments : \u001b[36m252683713\u001b[0m \u001b[0m                                           ||\n",
      "||    Successfully assigned alignments : \u001b[36m9694233 (3.8%)\u001b[0m \u001b[0m                      ||\n",
      "||    Running time : \u001b[36m0.13 minutes\u001b[0m \u001b[0m                                            ||\n",
      "||  \u001b[0m                                                                          ||\n",
      "|| Write the final count table. \u001b[0m                                              ||\n",
      "|| Write the read assignment summary. \u001b[0m                                        ||\n",
      "||  \u001b[0m                                                                          ||\n",
      "|| Summary of counting results can be found in file \"hisat_counts.tsv.summar \u001b[0m ||\n",
      "|| y\" \u001b[0m                                                                        ||\n",
      "||  \u001b[0m                                                                          ||\n",
      "\\\\============================================================================//\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!picard MarkDuplicates -I ../6_alignment/alignment/hisat/merged.bam -M logs/hisat_duplicates -O dedup/hisat.bam --VALIDATION_STRINGENCY SILENT\n",
    "\n",
    "!featureCounts -T 32 \\\n",
    "    /data/classes/2024/fall/biol343/course_files/dedup/hisat.bam \\\n",
    "    -T 32 \\\n",
    "    --byReadGroup \\\n",
    "    -s 1 \\\n",
    "    --ignoreDup \\\n",
    "    -M \\\n",
    "    --fraction \\\n",
    "    -a ../2_genome_exploration/genome/annotations.gtf \\\n",
    "    -o hisat_counts.tsv \\\n",
    "    --verbose"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the new numbers:\n",
    "\n",
    "| Analysis | INT_im1 | INT_im2 | INT_im3 | INT_ma1 | INT_ma2 | INT_ma3 | LIV_im1 | LIV_im2 | LIV_im3 | LIV_ma1 | LIV_ma2 | LIV_ma3 |\n",
    "|----------|---------|---------|---------|---------|---------|---------|---------|---------|---------|---------|---------|---------|\n",
    "| Theirs   | 2.84\t | 2.35\t   | 20.46 \t | 29.45   | 49.03   | 16.17   | 258.46  | 11.50   | 11.67   | 227.95  | 94.20   | 63.37   |\n",
    "| Ours (STAR)    | 0.5     | 1       | 12.3    | 8.67    | 8       | 1       | 218.48  | 2.38    | 4       | 269.16  | 76.61   | 36.19   |\n",
    "| Ours (HISAT)   | 2     | 0.5       | 25.2    | 41.2    | 34.4       | 8.5       | 1095.48  | 15.7    | 17.5       | 2368.03  | 524.07   | 304.8   |\n",
    "\n",
    "Finally, we can use MultiQC to aggregate the report, which will now include MarkDuplicates and featureCounts logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[91m///\u001b[0m \u001b]8;id=123635;https://multiqc.info\u001b\\\u001b[1mMultiQC\u001b[0m\u001b]8;;\u001b\\ 🔍 \u001b[2m| v1.17\u001b[0m\n",
      "\n",
      "\u001b[34m|           multiqc\u001b[0m | Prepending directory to sample names\n",
      "\u001b[34m|           multiqc\u001b[0m | Search path : /data/users/corwinbm5021/BIOL343/5_fastq/fastq/qc\n",
      "\u001b[34m|           multiqc\u001b[0m | Search path : /data/users/corwinbm5021/BIOL343/5_fastq/trimmed/qc\n",
      "\u001b[34m|           multiqc\u001b[0m | Search path : /data/users/corwinbm5021/BIOL343/6_alignment\n",
      "\u001b[34m|           multiqc\u001b[0m | Search path : /data/users/corwinbm5021/BIOL343/7_alignment_qc\n",
      "\u001b[34m|           multiqc\u001b[0m | Search path : /data/users/corwinbm5021/BIOL343/8_counting\n",
      "\u001b[2K\u001b[34m|\u001b[0m         \u001b[34msearching\u001b[0m | \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[32m208/208\u001b[0m  [0m \u001b[2m./star_counts.tsv\u001b[0m\n",
      "\u001b[?25h\u001b[34m|    feature_counts\u001b[0m | Found 1 reports\n",
      "\u001b[34m|          samtools\u001b[0m | Found 1 stats reports\n",
      "\u001b[34m|          samtools\u001b[0m | Found 1 flagstat reports\n",
      "\u001b[34m|              star\u001b[0m | Found 3 reports\n",
      "\u001b[34m|            hisat2\u001b[0m | Found 55 reports\n",
      "\u001b[34m|            fastqc\u001b[0m | Found 24 reports\n",
      "\u001b[34m|           multiqc\u001b[0m | Report      : multiqc_report.html\n",
      "\u001b[34m|           multiqc\u001b[0m | Data        : multiqc_data\n",
      "\u001b[34m|           multiqc\u001b[0m | MultiQC complete\n"
     ]
    }
   ],
   "source": [
    "!multiqc --force -d ../5_fastq/fastq/qc/ ../5_fastq/trimmed/qc/ ../6_alignment ../7_alignment_qc ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biol343",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
