{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating counts from an alignment\n",
    "\n",
    "Counting is more straightforward than alignment, but it's still very important and a bioinformatician has to think carefully about how to go about this process. Remember, identifying differnetially expressed genes relies upon the statistical comparison of the number of reads assigned to genes, compared among samples. \n",
    "\n",
    "We will be using `featureCounts` to count reads. `StringTie` is another popular counter. Install `subread` (of which `featureCounts` is a submodule) with `conda install bioconda::subread`.\n",
    "\n",
    "After installing, take a look at the `featureCounts` manual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Version 2.0.6\n",
      "\n",
      "Usage: featureCounts [options] -a <annotation_file> -o <output_file> input_file1 [input_file2] ... \n",
      "\n",
      "## Mandatory arguments:\n",
      "\n",
      "  -a <string>         Name of an annotation file. GTF/GFF format by default. See\n",
      "                      -F option for more format information. Inbuilt annotations\n",
      "                      (SAF format) is available in 'annotation' directory of the\n",
      "                      package. Gzipped file is also accepted.\n",
      "\n",
      "  -o <string>         Name of output file including read counts. A separate file\n",
      "                      including summary statistics of counting results is also\n",
      "                      included in the output ('<string>.summary'). Both files\n",
      "                      are in tab delimited format.\n",
      "\n",
      "  input_file1 [input_file2] ...   A list of SAM or BAM format files. They can be\n",
      "                      either name or location sorted. If no files provided,\n",
      "                      <stdin> input is expected. Location-sorted paired-end reads\n",
      "                      are automatically sorted by read names.\n",
      "\n",
      "## Optional arguments:\n",
      "# Annotation\n",
      "\n",
      "  -F <string>         Specify format of the provided annotation file. Acceptable\n",
      "                      formats include 'GTF' (or compatible GFF format) and\n",
      "                      'SAF'. 'GTF' by default.  For SAF format, please refer to\n",
      "                      Users Guide.\n",
      "\n",
      "  -t <string>         Specify feature type(s) in a GTF annotation. If multiple\n",
      "                      types are provided, they should be separated by ',' with\n",
      "                      no space in between. 'exon' by default. Rows in the\n",
      "                      annotation with a matched feature will be extracted and\n",
      "                      used for read mapping. \n",
      "\n",
      "  -g <string>         Specify attribute type in GTF annotation. 'gene_id' by \n",
      "                      default. Meta-features used for read counting will be \n",
      "                      extracted from annotation using the provided value.\n",
      "\n",
      "  --extraAttributes   Extract extra attribute types from the provided GTF\n",
      "                      annotation and include them in the counting output. These\n",
      "                      attribute types will not be used to group features. If\n",
      "                      more than one attribute type is provided they should be\n",
      "                      separated by comma.\n",
      "\n",
      "  -A <string>         Provide a chromosome name alias file to match chr names in\n",
      "                      annotation with those in the reads. This should be a two-\n",
      "                      column comma-delimited text file. Its first column should\n",
      "                      include chr names in the annotation and its second column\n",
      "                      should include chr names in the reads. Chr names are case\n",
      "                      sensitive. No column header should be included in the\n",
      "                      file.\n",
      "\n",
      "# Level of summarization\n",
      "\n",
      "  -f                  Perform read counting at feature level (eg. counting \n",
      "                      reads for exons rather than genes).\n",
      "\n",
      "# Overlap between reads and features\n",
      "\n",
      "  -O                  Assign reads to all their overlapping meta-features (or \n",
      "                      features if -f is specified).\n",
      "\n",
      "  --minOverlap <int>  Minimum number of overlapping bases in a read that is\n",
      "                      required for read assignment. 1 by default. Number of\n",
      "                      overlapping bases is counted from both reads if paired\n",
      "                      end. If a negative value is provided, then a gap of up\n",
      "                      to specified size will be allowed between read and the\n",
      "                      feature that the read is assigned to.\n",
      "\n",
      "  --fracOverlap <float> Minimum fraction of overlapping bases in a read that is\n",
      "                      required for read assignment. Value should be within range\n",
      "                      [0,1]. 0 by default. Number of overlapping bases is\n",
      "                      counted from both reads if paired end. Both this option\n",
      "                      and '--minOverlap' option need to be satisfied for read\n",
      "                      assignment.\n",
      "\n",
      "  --fracOverlapFeature <float> Minimum fraction of overlapping bases in a\n",
      "                      feature that is required for read assignment. Value\n",
      "                      should be within range [0,1]. 0 by default.\n",
      "\n",
      "  --largestOverlap    Assign reads to a meta-feature/feature that has the \n",
      "                      largest number of overlapping bases.\n",
      "\n",
      "  --nonOverlap <int>  Maximum number of non-overlapping bases in a read (or a\n",
      "                      read pair) that is allowed when being assigned to a\n",
      "                      feature. No limit is set by default.\n",
      "\n",
      "  --nonOverlapFeature <int> Maximum number of non-overlapping bases in a feature\n",
      "                      that is allowed in read assignment. No limit is set by\n",
      "                      default.\n",
      "\n",
      "  --readExtension5 <int> Reads are extended upstream by <int> bases from their\n",
      "                      5' end.\n",
      "\n",
      "  --readExtension3 <int> Reads are extended upstream by <int> bases from their\n",
      "                      3' end.\n",
      "\n",
      "  --read2pos <5:3>    Reduce reads to their 5' most base or 3' most base. Read\n",
      "                      counting is then performed based on the single base the \n",
      "                      read is reduced to.\n",
      "\n",
      "# Multi-mapping reads\n",
      "\n",
      "  -M                  Multi-mapping reads will also be counted. For a multi-\n",
      "                      mapping read, all its reported alignments will be \n",
      "                      counted. The 'NH' tag in BAM/SAM input is used to detect \n",
      "                      multi-mapping reads.\n",
      "\n",
      "# Fractional counting\n",
      "\n",
      "  --fraction          Assign fractional counts to features. This option must\n",
      "                      be used together with '-M' or '-O' or both. When '-M' is\n",
      "                      specified, each reported alignment from a multi-mapping\n",
      "                      read (identified via 'NH' tag) will carry a fractional\n",
      "                      count of 1/x, instead of 1 (one), where x is the total\n",
      "                      number of alignments reported for the same read. When '-O'\n",
      "                      is specified, each overlapping feature will receive a\n",
      "                      fractional count of 1/y, where y is the total number of\n",
      "                      features overlapping with the read. When both '-M' and\n",
      "                      '-O' are specified, each alignment will carry a fractional\n",
      "                      count of 1/(x*y).\n",
      "\n",
      "# Read filtering\n",
      "\n",
      "  -Q <int>            The minimum mapping quality score a read must satisfy in\n",
      "                      order to be counted. For paired-end reads, at least one\n",
      "                      end should satisfy this criteria. 0 by default.\n",
      "\n",
      "  --splitOnly         Count split alignments only (ie. alignments with CIGAR\n",
      "                      string containing 'N'). An example of split alignments is\n",
      "                      exon-spanning reads in RNA-seq data.\n",
      "\n",
      "  --nonSplitOnly      If specified, only non-split alignments (CIGAR strings do\n",
      "                      not contain letter 'N') will be counted. All the other\n",
      "                      alignments will be ignored.\n",
      "\n",
      "  --primary           Count primary alignments only. Primary alignments are \n",
      "                      identified using bit 0x100 in SAM/BAM FLAG field.\n",
      "\n",
      "  --ignoreDup         Ignore duplicate reads in read counting. Duplicate reads \n",
      "                      are identified using bit Ox400 in BAM/SAM FLAG field. The \n",
      "                      whole read pair is ignored if one of the reads is a \n",
      "                      duplicate read for paired end data.\n",
      "\n",
      "# Strandness\n",
      "\n",
      "  -s <int or string>  Perform strand-specific read counting. A single integer\n",
      "                      value (applied to all input files) or a string of comma-\n",
      "                      separated values (applied to each corresponding input\n",
      "                      file) should be provided. Possible values include:\n",
      "                      0 (unstranded), 1 (stranded) and 2 (reversely stranded).\n",
      "                      Default value is 0 (ie. unstranded read counting carried\n",
      "                      out for all input files).\n",
      "\n",
      "# Exon-exon junctions\n",
      "\n",
      "  -J                  Count number of reads supporting each exon-exon junction.\n",
      "                      Junctions were identified from all the exon-spanning reads\n",
      "                      in the input (containing 'N' in CIGAR string). Counting\n",
      "                      results are saved to a file named '<output_file>.jcounts'\n",
      "\n",
      "  -G <string>         Provide the name of a FASTA-format file that contains the\n",
      "                      reference sequences used in read mapping that produced the\n",
      "                      provided SAM/BAM files. This optional argument can be used\n",
      "                      with '-J' option to improve read counting for junctions.\n",
      "\n",
      "# Parameters specific to paired end reads\n",
      "\n",
      "  -p                  If specified, libraries are assumed to contain paired-end\n",
      "                      reads. For any library that contains paired-end reads, the\n",
      "                      'countReadPairs' parameter controls if read pairs or reads\n",
      "                      should be counted.\n",
      "\n",
      "  --countReadPairs    If specified, fragments (or templates) will be counted\n",
      "                      instead of reads. This option is only applicable for\n",
      "                      paired-end reads. For single-end data, it is ignored.\n",
      "\n",
      "  -B                  Only count read pairs that have both ends aligned.\n",
      "\n",
      "  -P                  Check validity of paired-end distance when counting read \n",
      "                      pairs. Use -d and -D to set thresholds.\n",
      "\n",
      "  -d <int>            Minimum fragment/template length, 50 by default.\n",
      "\n",
      "  -D <int>            Maximum fragment/template length, 600 by default.\n",
      "\n",
      "  -C                  Do not count read pairs that have their two ends mapping \n",
      "                      to different chromosomes or mapping to same chromosome \n",
      "                      but on different strands.\n",
      "\n",
      "  --donotsort         Do not sort reads in BAM/SAM input. Note that reads from \n",
      "                      the same pair are required to be located next to each \n",
      "                      other in the input.\n",
      "\n",
      "# Number of CPU threads\n",
      "\n",
      "  -T <int>            Number of the threads. 1 by default.\n",
      "\n",
      "# Read groups\n",
      "\n",
      "  --byReadGroup       Assign reads by read group. \"RG\" tag is required to be\n",
      "                      present in the input BAM/SAM files.\n",
      "                      \n",
      "\n",
      "# Long reads\n",
      "\n",
      "  -L                  Count long reads such as Nanopore and PacBio reads. Long\n",
      "                      read counting can only run in one thread and only reads\n",
      "                      (not read-pairs) can be counted. There is no limitation on\n",
      "                      the number of 'M' operations allowed in a CIGAR string in\n",
      "                      long read counting.\n",
      "\n",
      "# Assignment results for each read\n",
      "\n",
      "  -R <format>         Output detailed assignment results for each read or read-\n",
      "                      pair. Results are saved to a file that is in one of the\n",
      "                      following formats: CORE, SAM and BAM. See Users Guide for\n",
      "                      more info about these formats.\n",
      "\n",
      "  --Rpath <string>    Specify a directory to save the detailed assignment\n",
      "                      results. If unspecified, the directory where counting\n",
      "                      results are saved is used.\n",
      "\n",
      "# Miscellaneous\n",
      "\n",
      "  --tmpDir <string>   Directory under which intermediate files are saved (later\n",
      "                      removed). By default, intermediate files will be saved to\n",
      "                      the directory specified in '-o' argument.\n",
      "\n",
      "  --maxMOp <int>      Maximum number of 'M' operations allowed in a CIGAR\n",
      "                      string. 10 by default. Both 'X' and '=' are treated as 'M'\n",
      "                      and adjacent 'M' operations are merged in the CIGAR\n",
      "                      string.\n",
      "\n",
      "  --verbose           Output verbose information for debugging, such as un-\n",
      "                      matched chromosome/contig names.\n",
      "\n",
      "  -v                  Output version of the program.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!featureCounts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are analyzing data produced in the [Winners vs. Losers paper](https://journals.plos.org/plospathogens/article?id=10.1371/journal.ppat.1012268), which analyzed the expression differences between schistosome eggs that were trapped in the liver and eggs that were trapped in the intestine. Luckily for us, the methods section contains a few details about their use of `featureCounts`:\n",
    "\n",
    "> The UMIs were deduplicated using open source UMI-tools software package (version 1.1.2) [64]. Deduplicated mapped reads were counted on the gene level using FeatureCounts (version 2.0.1) [65] with options -M and‚Äìfraction (counting of multi-mapped reads with expression value as a fraction based on the number of genes assigned, ranging from 2‚Äì20 genes).\n",
    "\n",
    "You can see from the man page above that the `-M` flag allows for multi-mappers to be counted - these are reads that mapped to multiple different locations with equal quality scores. The `--fraction` argument tells the program how to account for multi-mapped reads:\n",
    "\n",
    "> When '-M' is specified, each reported alignment from a multi-mapping read (identified via 'NH' tag) will carry a fractional count of 1/x, instead of 1 (one), where x is the total number of alignments reported for the same read.\n",
    "\n",
    "So, if we have a read that mapped to two different genes, those two reads will count for 0.5 for each gene that it aligned to.\n",
    "\n",
    "## Dealing with duplicate reads\n",
    "\n",
    "So far, we have dealt with duplicate reads, even though we know from FASTQC that we had many duplicates. In the below example, over 60% of the reads were duplicates:\n",
    "\n",
    "<img src=\"assets/duplicates_2.png\" width=\"400\">\n",
    "\n",
    "Indeed, this was true of all samples:\n",
    "\n",
    "<img src=\"assets/duplicates.png\" width=\"400\">\n",
    "\n",
    "There are a few different reasons for why a sample would have many duplicate reads. The biggest reason is that, during library prep, there was a log amount of input RNA. This means that when the library is finished with the PCR enrichment steps, the library fragments are amplified so many times that many of the reads derived from duplicate fragments:\n",
    "\n",
    "<img src=\"assets/pcr.png\" width=\"400\">\n",
    "\n",
    "Many duplicate reads are a hallmark of RNA-seq experiments where the original tissue source was small, which resulted in low amounts of RNA being extracted. There are many different steps at which you can remove duplicates. Some people remove them from the FASTQ during trimming/filter, but my opinion is that is unnecessary and can potentially remove data that you might later be interested in. I think it's better to align the duplicates but mark them (rather than removing them) so that they aren't counted during the counting step. If you look at last week's [notebook on SAM/BAM QC](../7_alignment_qc/7_alignment_qc.ipynb), you'll see that the bit flag 0x400 represents a duplicate read. So, we can use a tool to update the read's flag if it is suspected to be a duplicate.\n",
    "\n",
    "To do this, we will first use [Picard Tools to mark the duplicate reads](https://gatk.broadinstitute.org/hc/en-us/articles/360037052812-MarkDuplicates-Picard); then we'll tell featureCounts to ignore anything marked as a duplicate (with the the `--ignoreDup` flag). This flag will analyze the FLAG field in the BAM and ignore any alignment that contains the duplicate bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‚Äòlogs‚Äô: File exists\n",
      "mkdir: cannot create directory ‚Äòdedup‚Äô: File exists\n",
      "Error: LinkageError occurred while loading main class picard.cmdline.PicardCommandLine\n",
      "\tjava.lang.UnsupportedClassVersionError: picard/cmdline/PicardCommandLine has been compiled by a more recent version of the Java Runtime (class file version 61.0), this version of the Java Runtime only recognizes class file versions up to 55.0\n"
     ]
    }
   ],
   "source": [
    "%mkdir logs\n",
    "%mkdir dedup\n",
    "\n",
    "!picard MarkDuplicates -I /data/classes/2024/fall/biol343/course_files/alignment/star -M logs/star_duplicates -O dedup/star.bam --VALIDATION_STRINGENCY SILENT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***20 minutes to complete***\n",
    "\n",
    "Finally, we are also going to use the stranded argument because the QuantSeq FWD 3‚ÄômRNA Library Prep Kit is a stranded kit. That is, the library was created such that we can be 100% confident that each fragment that we sequenced represents the same sequences as the template mRNA. Here's the final `featureCounts` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       \u001b[44;37m ========== \u001b[0m\u001b[36m    _____ _    _ ____  _____  ______          _____  \n",
      "       \u001b[44;37m =====      \u001b[0m\u001b[36m   / ____| |  | |  _ \\|  __ \\|  ____|   /\\   |  __ \\ \n",
      "       \u001b[44;37m   =====    \u001b[0m\u001b[36m  | (___ | |  | | |_) | |__) | |__     /  \\  | |  | |\n",
      "       \u001b[44;37m     ====   \u001b[0m\u001b[36m   \\___ \\| |  | |  _ <|  _  /|  __|   / /\\ \\ | |  | |\n",
      "       \u001b[44;37m       ==== \u001b[0m\u001b[36m   ____) | |__| | |_) | | \\ \\| |____ / ____ \\| |__| |\n",
      "       \u001b[44;37m ========== \u001b[0m\u001b[36m  |_____/ \\____/|____/|_|  \\_\\______/_/    \\_\\_____/\u001b[0m\n",
      "\t  v2.0.6\n",
      "\n",
      "//==========================\u001b[36m featureCounts setting \u001b[0m===========================\\\\\n",
      "||  \u001b[0m                                                                          ||\n",
      "||             Input files : \u001b[36m1 BAM file  \u001b[0m \u001b[0m                                    ||\n",
      "||  \u001b[0m                                                                          ||\n",
      "||                           \u001b[36mstar.bam\u001b[0m \u001b[0m                                        ||\n",
      "||  \u001b[0m                                                                          ||\n",
      "||             Output file : \u001b[36mstar_counts.tsv\u001b[0m \u001b[0m                                 ||\n",
      "||                 Summary : \u001b[36mstar_counts.tsv.summary\u001b[0m \u001b[0m                         ||\n",
      "||              Paired-end : \u001b[36mno\u001b[0m \u001b[0m                                              ||\n",
      "||        Count read pairs : \u001b[36mno\u001b[0m \u001b[0m                                              ||\n",
      "||              Annotation : \u001b[36mannotations.gtf (GTF)\u001b[0m \u001b[0m                           ||\n",
      "||      Dir for temp files : \u001b[36m./\u001b[0m \u001b[0m                                              ||\n",
      "||  \u001b[0m                                                                          ||\n",
      "||                 Threads : \u001b[36m32\u001b[0m \u001b[0m                                              ||\n",
      "||                   Level : \u001b[36mmeta-feature level\u001b[0m \u001b[0m                              ||\n",
      "||      Multimapping reads : \u001b[36mcounted (fractional)\u001b[0m \u001b[0m                            ||\n",
      "|| Multi-overlapping reads : \u001b[36mnot counted\u001b[0m \u001b[0m                                     ||\n",
      "||   Min overlapping bases : \u001b[36m1\u001b[0m \u001b[0m                                               ||\n",
      "||        Duplicated Reads : \u001b[36mignored\u001b[0m \u001b[0m                                         ||\n",
      "||  \u001b[0m                                                                          ||\n",
      "\\\\============================================================================//\n",
      "\n",
      "//=================================\u001b[36m Running \u001b[0m==================================\\\\\n",
      "||  \u001b[0m                                                                          ||\n",
      "|| Load annotation file annotations.gtf \u001b[0m... \u001b[0m                                  ||\n",
      "||    Features : \u001b[36m88812\u001b[0m \u001b[0m                                                       ||\n",
      "||    Meta-features : \u001b[36m9920\u001b[0m \u001b[0m                                                   ||\n",
      "||    Chromosomes/contigs : \u001b[36m10\u001b[0m \u001b[0m                                               ||\n",
      "||  \u001b[0m                                                                          ||\n",
      "|| Process BAM file star.bam... \u001b[0m                                              ||\n",
      "||    Strand specific : \u001b[36mstranded\u001b[0m \u001b[0m                                             ||\n",
      "||    Single-end reads are included. \u001b[0m                                         ||\n",
      "||    Total read groups : \u001b[36m12\u001b[0m \u001b[0m                                                 ||\n",
      "||    Total alignments : \u001b[36m171342056\u001b[0m \u001b[0m                                           ||\n",
      "||    Successfully assigned alignments : \u001b[36m19944959 (11.6%)\u001b[0m \u001b[0m                    ||\n",
      "||    Running time : \u001b[36m0.08 minutes\u001b[0m \u001b[0m                                            ||\n",
      "||  \u001b[0m                                                                          ||\n",
      "|| Write the final count table. \u001b[0m                                              ||\n",
      "|| Write the read assignment summary. \u001b[0m                                        ||\n",
      "||  \u001b[0m                                                                          ||\n",
      "|| Summary of counting results can be found in file \"star_counts.tsv.summary \u001b[0m ||\n",
      "|| \" \u001b[0m                                                                         ||\n",
      "||  \u001b[0m                                                                          ||\n",
      "\\\\============================================================================//\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!featureCounts -T 32 \\\n",
    "    /data/classes/2024/fall/biol343/course_files/dedup/star.bam \\\n",
    "    -T 32 \\\n",
    "    --byReadGroup \\\n",
    "    -s 1 \\\n",
    "    --ignoreDup \\\n",
    "    -M \\\n",
    "    --fraction \\\n",
    "    -a ../2_genome_exploration/genome/annotations.gtf \\\n",
    "    -o star_counts.tsv \\\n",
    "    --verbose"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now are finally at a point in the analysis in which we can compare our results with the results published in the Winners vs. Losers paper. One of their most prominent results was showing the immunomodulatory gene Smp_245390 was more highly expressed in mature liver eggs than mature intestinal eggs:\n",
    "\n",
    "<img src=\"assets/fig4d.png\" width=\"400\">\n",
    "\n",
    "The paper also included their own counting results in [S2 Table](https://journals.plos.org/plospathogens/article/file?type=supplementary&id=10.1371/journal.ppat.1012268.s002). Here are their results and our results compared:\n",
    "\n",
    "| Analysis | INT_im1 | INT_im2 | INT_im3 | INT_ma1 | INT_ma2 | INT_ma3 | LIV_im1 | LIV_im2 | LIV_im3 | LIV_ma1 | LIV_ma2 | LIV_ma3 |\n",
    "|----------|---------|---------|---------|---------|---------|---------|---------|---------|---------|---------|---------|---------|\n",
    "| Theirs   | 2.84\t | 2.35\t   | 20.46 \t | 29.45   | 49.03   | 16.17   | 258.46  | 11.50   | 11.67   | 227.95  | 94.20   | 63.37   |\n",
    "| Ours     | 0.5     | 1       | 12.3    | 8.67    | 8       | 1       | 218.48  | 2.38    | 4       | 269.16  | 76.61   | 36.19   |\n",
    "\n",
    "Looks pretty good! Our counts are lower than theirs across the board (other than LIV_ma1), but the main patterns hold true. Based on these numbers, it will look like our analysis is likely to reproduce the main finding from the paper - that Smp_245390 is significantly more highly exprssed in mature liver eggs than mature intestine eggs.\n",
    "\n",
    "Let's now do all of that again, but with the HISAT alignment..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!picard MarkDuplicates -I ../6_alignment/alignment/hisat/merged.bam -M logs/hisat_duplicates -O dedup/hisat.bam --VALIDATION_STRINGENCY SILENT\n",
    "\n",
    "!featureCounts -T 32 \\\n",
    "    dedup/hisat.bam \\\n",
    "    -T 32 \\\n",
    "    --byReadGroup \\\n",
    "    -s 1 \\\n",
    "    --ignoreDup \\\n",
    "    -M \\\n",
    "    --fraction \\\n",
    "    -a ../2_genome_exploration/genome/annotations.gtf \\\n",
    "    -o hisat_counts.tsv \\\n",
    "    --verbose"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the new numbers:\n",
    "\n",
    "| Analysis | INT_im1 | INT_im2 | INT_im3 | INT_ma1 | INT_ma2 | INT_ma3 | LIV_im1 | LIV_im2 | LIV_im3 | LIV_ma1 | LIV_ma2 | LIV_ma3 |\n",
    "|----------|---------|---------|---------|---------|---------|---------|---------|---------|---------|---------|---------|---------|\n",
    "| Theirs   | 2.84\t | 2.35\t   | 20.46 \t | 29.45   | 49.03   | 16.17   | 258.46  | 11.50   | 11.67   | 227.95  | 94.20   | 63.37   |\n",
    "| Ours (STAR)    | 0.5     | 1       | 12.3    | 8.67    | 8       | 1       | 218.48  | 2.38    | 4       | 269.16  | 76.61   | 36.19   |\n",
    "| Ours (HISAT)   | 2     | 0.5       | 25.2    | 41.2    | 34.4       | 8.5       | 1095.48  | 15.7    | 17.5       | 2368.03  | 524.07   | 304.8   |\n",
    "\n",
    "Finally, we can use MultiQC to aggregate the report, which will now include MarkDuplicates and featureCounts logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[91m///\u001b[0m \u001b]8;id=878589;https://multiqc.info\u001b\\\u001b[1mMultiQC\u001b[0m\u001b]8;;\u001b\\ üîç \u001b[2m| v1.17\u001b[0m\n",
      "\n",
      "\u001b[34m|           multiqc\u001b[0m | Prepending directory to sample names\n",
      "\u001b[34m|           multiqc\u001b[0m | Search path : /data/users/mccallke0364/BIOL343/5_fastq/fastq/qc\n",
      "\u001b[34m|           multiqc\u001b[0m | Search path : /data/users/mccallke0364/BIOL343/5_fastq/trimmed/qc\n",
      "\u001b[34m|           multiqc\u001b[0m | Search path : /data/users/mccallke0364/BIOL343/6_alignment\n",
      "\u001b[34m|           multiqc\u001b[0m | Search path : /data/users/mccallke0364/BIOL343/7_alignment_qc\n",
      "\u001b[34m|           multiqc\u001b[0m | Search path : /data/users/mccallke0364/BIOL343/8_counting\n",
      "\u001b[2K\u001b[34m|\u001b[0m         \u001b[34msearching\u001b[0m | \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[35m100%\u001b[0m \u001b[32m91/91\u001b[0m  ment_qc/multiqc_report.html\u001b[0ms.txt\u001b[0m\n",
      "\u001b[?25h\u001b[34m|    feature_counts\u001b[0m | Found 1 reports\n",
      "\u001b[34m|          samtools\u001b[0m | Found 1 stats reports\n",
      "\u001b[34m|          samtools\u001b[0m | Found 1 flagstat reports\n",
      "\u001b[34m|              star\u001b[0m | Found 2 reports\n",
      "\u001b[34m|            hisat2\u001b[0m | Found 1 reports\n",
      "\u001b[34m|            fastqc\u001b[0m | Found 24 reports\n",
      "\u001b[34m|           multiqc\u001b[0m | Report      : multiqc_report.html\n",
      "\u001b[34m|           multiqc\u001b[0m | Data        : multiqc_data\n",
      "\u001b[34m|           multiqc\u001b[0m | MultiQC complete\n"
     ]
    }
   ],
   "source": [
    "!multiqc --force -d ../5_fastq/fastq/qc/ ../5_fastq/trimmed/qc/ ../6_alignment ../7_alignment_qc ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biol343",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
