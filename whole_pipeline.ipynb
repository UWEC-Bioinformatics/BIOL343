{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dc29958",
   "metadata": {},
   "source": [
    "# Get genome and annotations\n",
    "\n",
    "To prepare, adjust the user environmental variable (`$USER`) to be set to your user ID.\n",
    "\n",
    "1. Make a new directory called `genome`\n",
    "2. Navigate to `genome/`\n",
    "3. Download the reference genome file, which will be compressed as `.gz`\n",
    "    1. The `>` operator saves the incoming file to a new file name, which we call `genome.fa.gz`\n",
    "    2. Checkout details and info about the genome at [WormBase ParaSite](https://parasite.wormbase.org/Schistosoma_mansoni_prjea36577/Info/Index/)\n",
    "4. Decompress the reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eac3d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/users/wheelenj/biol343\n",
      "mkdir: cannot create directory ‘genome’: File exists\n",
      "/data/users/wheelenj/biol343/genome\n",
      "--2024-07-15 15:18:22--  https://ftp.ebi.ac.uk/pub/databases/wormbase/parasite/releases/WBPS19/species/schistosoma_mansoni/PRJEA36577/schistosoma_mansoni.PRJEA36577.WBPS19.genomic.fa.gz\n",
      "Resolving ftp.ebi.ac.uk (ftp.ebi.ac.uk)... 193.62.193.165\n",
      "Connecting to ftp.ebi.ac.uk (ftp.ebi.ac.uk)|193.62.193.165|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 116797085 (111M) [application/x-gzip]\n",
      "Saving to: ‘genome.fa.gz’\n",
      "\n",
      "genome.fa.gz          2%[                    ]   3.34M   592KB/s    eta 3m 11s ^C\n",
      "gzip: genome.fa already exists; do you wish to overwrite (y or n)? "
     ]
    }
   ],
   "source": [
    "%cd /data/users/wheelenj/biol343\n",
    "!mkdir genome\n",
    "%cd genome\n",
    "!wget -O genome.fa.gz https://ftp.ebi.ac.uk/pub/databases/wormbase/parasite/releases/WBPS19/species/schistosoma_mansoni/PRJEA36577/schistosoma_mansoni.PRJEA36577.WBPS19.genomic.fa.gz\n",
    "!gzip -d genome.fa.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35b4529",
   "metadata": {},
   "source": [
    "`grep` is a command line tool that is often used to inspect files, especially files that includes sequences (i.e., FastA/FastQ). \n",
    "\n",
    "View the `grep` manual and then use it to do the following:\n",
    "\n",
    "- Count the number of contigs/chromosomes\n",
    "- Take a look at the header of each contig/chromosome\n",
    "\n",
    "How many chromosomes are there, and what is the length of each?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "663ff87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: grep [OPTION]... PATTERN [FILE]...\n",
      "Search for PATTERN in each FILE.\n",
      "Example: grep -i 'hello world' menu.h main.c\n",
      "\n",
      "Pattern selection and interpretation:\n",
      "  -E, --extended-regexp     PATTERN is an extended regular expression\n",
      "  -F, --fixed-strings       PATTERN is a set of newline-separated strings\n",
      "  -G, --basic-regexp        PATTERN is a basic regular expression (default)\n",
      "  -P, --perl-regexp         PATTERN is a Perl regular expression\n",
      "  -e, --regexp=PATTERN      use PATTERN for matching\n",
      "  -f, --file=FILE           obtain PATTERN from FILE\n",
      "  -i, --ignore-case         ignore case distinctions\n",
      "  -w, --word-regexp         force PATTERN to match only whole words\n",
      "  -x, --line-regexp         force PATTERN to match only whole lines\n",
      "  -z, --null-data           a data line ends in 0 byte, not newline\n",
      "\n",
      "Miscellaneous:\n",
      "  -s, --no-messages         suppress error messages\n",
      "  -v, --invert-match        select non-matching lines\n",
      "  -V, --version             display version information and exit\n",
      "      --help                display this help text and exit\n",
      "\n",
      "Output control:\n",
      "  -m, --max-count=NUM       stop after NUM selected lines\n",
      "  -b, --byte-offset         print the byte offset with output lines\n",
      "  -n, --line-number         print line number with output lines\n",
      "      --line-buffered       flush output on every line\n",
      "  -H, --with-filename       print file name with output lines\n",
      "  -h, --no-filename         suppress the file name prefix on output\n",
      "      --label=LABEL         use LABEL as the standard input file name prefix\n",
      "  -o, --only-matching       show only the part of a line matching PATTERN\n",
      "  -q, --quiet, --silent     suppress all normal output\n",
      "      --binary-files=TYPE   assume that binary files are TYPE;\n",
      "                            TYPE is 'binary', 'text', or 'without-match'\n",
      "  -a, --text                equivalent to --binary-files=text\n",
      "  -I                        equivalent to --binary-files=without-match\n",
      "  -d, --directories=ACTION  how to handle directories;\n",
      "                            ACTION is 'read', 'recurse', or 'skip'\n",
      "  -D, --devices=ACTION      how to handle devices, FIFOs and sockets;\n",
      "                            ACTION is 'read' or 'skip'\n",
      "  -r, --recursive           like --directories=recurse\n",
      "  -R, --dereference-recursive\n",
      "                            likewise, but follow all symlinks\n",
      "      --include=FILE_PATTERN\n",
      "                            search only files that match FILE_PATTERN\n",
      "      --exclude=FILE_PATTERN\n",
      "                            skip files and directories matching FILE_PATTERN\n",
      "      --exclude-from=FILE   skip files matching any file pattern from FILE\n",
      "      --exclude-dir=PATTERN directories that match PATTERN will be skipped.\n",
      "  -L, --files-without-match print only names of FILEs with no selected lines\n",
      "  -l, --files-with-matches  print only names of FILEs with selected lines\n",
      "  -c, --count               print only a count of selected lines per FILE\n",
      "  -T, --initial-tab         make tabs line up (if needed)\n",
      "  -Z, --null                print 0 byte after FILE name\n",
      "\n",
      "Context control:\n",
      "  -B, --before-context=NUM  print NUM lines of leading context\n",
      "  -A, --after-context=NUM   print NUM lines of trailing context\n",
      "  -C, --context=NUM         print NUM lines of output context\n",
      "  -NUM                      same as --context=NUM\n",
      "      --group-separator=SEP use SEP as a group separator\n",
      "      --no-group-separator  use empty string as a group separator\n",
      "      --color[=WHEN],\n",
      "      --colour[=WHEN]       use markers to highlight the matching strings;\n",
      "                            WHEN is 'always', 'never', or 'auto'\n",
      "  -U, --binary              do not strip CR characters at EOL (MSDOS/Windows)\n",
      "\n",
      "When FILE is '-', read standard input.  With no FILE, read '.' if\n",
      "recursive, '-' otherwise.  With fewer than two FILEs, assume -h.\n",
      "Exit status is 0 if any line is selected, 1 otherwise;\n",
      "if any error occurs and -q is not given, the exit status is 2.\n",
      "\n",
      "Report bugs to: bug-grep@gnu.org\n",
      "GNU grep home page: <http://www.gnu.org/software/grep/>\n",
      "General help using GNU software: <http://www.gnu.org/gethelp/>\n"
     ]
    }
   ],
   "source": [
    "!grep --help\n",
    "\n",
    "# !grep -c '>' /data/users/wheelenj/biol343/genome/genome.fa\n",
    "# !grep '>' /data/users/wheelenj/biol343/genome/genome.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac887b2",
   "metadata": {},
   "source": [
    "This assembly is full-length (an impressive achievement, which you'll learn more about next semester 🤯), and has been assembled into the 7 autosomes, two sex chromosome (Z and W), and a mitochondrial genome.\n",
    "\n",
    "In addition to the genomic sequences, we also need the annotations file. Genome annotation files are tab-separated files that include coordinate information for all genomic annotations. For example, the start/stop location of every single gene, mRNA, and exon. Annotation are usually in GTF or GFF format; GTF is more common and preferred by many programs. [Here's the definition](http://mblab.wustl.edu/GTF22.html) for the GTF file format.\n",
    "\n",
    "Let's get the annotations and decompress them.\n",
    "\n",
    "- This time we'll pipe the commands, so we have to redirect the download to standard out (`-O -`).\n",
    "- The pipe operator `|` allows you to run a command using standard output from the previous command as the input.\n",
    "- To write a single command over multiple lines, use the `\\` sign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c306e667",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O - https://ftp.ebi.ac.uk/pub/databases/wormbase/parasite/releases/WBPS19/species/schistosoma_mansoni/PRJEA36577/schistosoma_mansoni.PRJEA36577.WBPS19.canonical_geneset.gtf.gz | \\\n",
    "    gzip -d > /data/users/wheelenj/biol343/genome/annotations.gtf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909e5457",
   "metadata": {},
   "source": [
    "Let's checkout what the annotations look like. The `head` and `tail` commands allow you to look at the first or last lines respectively. A numerical argument defines how many lines you want to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25f1af0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!genebuild-version 2022-11-WormBase\n",
      "SM_V10_1\tWormBase\tgene\t68427\t68783\t.\t-\t.\tgene_id \"Smp_329140\"; gene_version \"1\"; gene_source \"WormBase\"; gene_biotype \"protein_coding\";\n",
      "SM_V10_1\tWormBase\ttranscript\t68427\t68783\t.\t-\t.\tgene_id \"Smp_329140\"; gene_version \"1\"; transcript_id \"Smp_329140.1\"; gene_source \"WormBase\"; gene_biotype \"protein_coding\"; transcript_source \"WormBase\"; transcript_biotype \"protein_coding\"; tag \"Ensembl_canonical\";\n",
      "SM_V10_1\tWormBase\texon\t68427\t68783\t.\t-\t.\tgene_id \"Smp_329140\"; gene_version \"1\"; transcript_id \"Smp_329140.1\"; exon_number \"1\"; gene_source \"WormBase\"; gene_biotype \"protein_coding\"; transcript_source \"WormBase\"; transcript_biotype \"protein_coding\"; exon_id \"Smp_329140.1.e1\"; tag \"Ensembl_canonical\";\n",
      "SM_V10_1\tWormBase\tCDS\t68596\t68763\t.\t-\t0\tgene_id \"Smp_329140\"; gene_version \"1\"; transcript_id \"Smp_329140.1\"; exon_number \"1\"; gene_source \"WormBase\"; gene_biotype \"protein_coding\"; transcript_source \"WormBase\"; transcript_biotype \"protein_coding\"; protein_id \"Smp_329140.1\"; tag \"Ensembl_canonical\";\n",
      "SM_V10_1\tWormBase\tstart_codon\t68761\t68763\t.\t-\t0\tgene_id \"Smp_329140\"; gene_version \"1\"; transcript_id \"Smp_329140.1\"; exon_number \"1\"; gene_source \"WormBase\"; gene_biotype \"protein_coding\"; transcript_source \"WormBase\"; transcript_biotype \"protein_coding\"; tag \"Ensembl_canonical\";\n",
      "SM_V10_1\tWormBase\tstop_codon\t68593\t68595\t.\t-\t0\tgene_id \"Smp_329140\"; gene_version \"1\"; transcript_id \"Smp_329140.1\"; exon_number \"1\"; gene_source \"WormBase\"; gene_biotype \"protein_coding\"; transcript_source \"WormBase\"; transcript_biotype \"protein_coding\"; tag \"Ensembl_canonical\";\n",
      "SM_V10_1\tWormBase\tfive_prime_utr\t68764\t68783\t.\t-\t.\tgene_id \"Smp_329140\"; gene_version \"1\"; transcript_id \"Smp_329140.1\"; gene_source \"WormBase\"; gene_biotype \"protein_coding\"; transcript_source \"WormBase\"; transcript_biotype \"protein_coding\"; tag \"Ensembl_canonical\";\n",
      "SM_V10_1\tWormBase\tthree_prime_utr\t68427\t68592\t.\t-\t.\tgene_id \"Smp_329140\"; gene_version \"1\"; transcript_id \"Smp_329140.1\"; gene_source \"WormBase\"; gene_biotype \"protein_coding\"; transcript_source \"WormBase\"; transcript_biotype \"protein_coding\"; tag \"Ensembl_canonical\";\n",
      "SM_V10_1\tWormBase\tgene\t83503\t131262\t.\t-\t.\tgene_id \"Smp_315690\"; gene_version \"1\"; gene_source \"WormBase\"; gene_biotype \"protein_coding\";\n"
     ]
    }
   ],
   "source": [
    "!head -10 /data/users/wheelenj/biol343/genome/annotations.gtf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff757a4",
   "metadata": {},
   "source": [
    "Each line is a different annotation. In the first 10 lines we see gene, exon, CDS, start codon, stop codon, 5' UTR, and 3' UTR. The columns (technically \"fields\") of a GTF file are described at the link provided above. Fields are tab-separated. `grep` can again be used to search for annotations of interest, but this time we have to use a few regular expressions. For example, suppose we want to know how many transcripts are expressed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537b7ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep -c \"transcript\" /data/users/wheelenj/biol343/genome/annotations.gtf\n",
    "!grep -c -P \"\\ttranscript\\t\" /data/users/wheelenj/biol343/genome/annotations.gtf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642a4f70",
   "metadata": {},
   "source": [
    "If we only search for \"transcript,\" we'll get results for \"transcript_biotype\", \"transcript_source\", etc. There are far fewer than 231617 transcripts in this genome. To search for only \"transcript\" when it's alone in a field (that is, surrounded by tabs), we have to use a regular expression and tell `grep` we're doing so with the `-P` flag.\n",
    "\n",
    "We can this same idea to count how many genes are on chromosome 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d12e31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep -c -P \"SM_V10_1.*\\tgene\\t\" /data/users/wheelenj/biol343/genome/annotations.gtf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c375ee",
   "metadata": {},
   "source": [
    "You can combine `grep` and `cut` to extract fields from specific lines. For instance, suppose you're interested in the gene called Smp_104210, which is a an opsin protein (the receptor that detects photons in eyes or eye-spots). The following command would show you all the lines that contained that gene ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082910b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep 'Smp_104210' /data/users/wheelenj/biol343/genome/annotations.gtf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85c3acf",
   "metadata": {},
   "source": [
    "Now suppose you wanted the start position of the trasnscript associated with Smp_104210. We know from the GTF description that the 3rd field contains the feature type and the 4th field contains the start location. `cut` allows you to parse each field of a delimited file. `grep` exracts lines containing the search term, which can then be piped to `cut` to extract the feature, and then `grep` can again be used to only keep mRNA features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954ab91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep 'Smp_104210' /data/users/wheelenj/biol343/genome/annotations.gtf | cut -f 3,4 | grep 'transcript'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3307d7c2",
   "metadata": {},
   "source": [
    "# FastQ download and QC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfc2a04",
   "metadata": {},
   "source": [
    "We have the genome and annotations. The RNA-seq data will be mapped to this reference, and then we can count how many RNA-seq reads align to the annotations we care about (genes or transcripts). Now we need to get the FastQ files that we want to align and analyze.\n",
    "- Create a new directory called `fastq`\n",
    "- Get the SRA Run Table, which give the metadata for the FastQ files.\n",
    "    - *This will include a `cp` command to move it from the class dir to the user dir*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b7c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir /data/users/wheelenj/biol343/fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfeb22cd",
   "metadata": {},
   "source": [
    "Let's take a look at the run table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bfccd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -15 /data/users/wheelenj/biol343/fastq/SraRunTable.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3a1ee8",
   "metadata": {},
   "source": [
    "You can see that there are 12 different runs, each has an ID that looks something like `SRR26691082`. After the ID, quite a bit of run metadata is provided. You should spend some time learning about what each field denotes.\n",
    "\n",
    "As we know, the experiment had four different samples: \n",
    "- liver immature\n",
    "- liver mature\n",
    "- intestine immature\n",
    "- intestine mature\n",
    "\n",
    "This information is provided in the metadata. We are all going to work with all 12 runs.\n",
    "\n",
    "First we have to use `sra-tools` to download the FastQ files from NCBI's SRA database. To so, we'll use a `for` loop within bash. We can use `cut` to get the first field, but because it's comma-delimited instead of tab-delimited, we have to tell the program with the `-d` option. This can be saved to a file, which then can be looped through line-by-line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f8640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cut -d ',' -f 1 /data/users/wheelenj/biol343/fastq/SraRunTable.txt | tail -n +2 > /data/users/wheelenj/biol343/fastq/sra_list.txt\n",
    "!while IFS= read -r line; do \\\n",
    "    echo \"Getting $line from NCBI SRA\"; \\\n",
    "    parallel-fastq-dump --sra-id $line --threads 16 --outdir . --gzip; \\\n",
    "    done < sra_list.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf1afc4",
   "metadata": {},
   "source": [
    "If we take another look at the metadata, there are a few things that are of interest to us and our analysis. First, these reads were generated with `PolyA` selection, which means reads should have many A's on their 3' end. Second, the reads are `ILLUMINA` reads generated on a `NextSeq 500` instrument, which means they may have Illumina adapters; depending on whether or not they were trimmed by the authors prior to uploading them to SRA. Third, from the paper (but not the run table), we know that these are single-end reads. This metadata will be important to us soon.\n",
    "\n",
    "Whenever we look at FastQ files for the first time, we should perform quality control (QC). The primary tool used for read QC is called FastQC, which is installed in our environment. Let's take a look at the manual and then run QC on our reads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa35d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!fastqc -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fb3adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /data/users/wheelenj/biol343/fastq\n",
    "!fastqc -t 16 *.fastq.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6871b2",
   "metadata": {},
   "source": [
    "You should have a decent idea what each of these QC metrics mean. For our immediate purposes, there are a few things to pay attention to:\n",
    "\n",
    "1. Base sequence quality gets lower toward the end of the read.\n",
    "2. The beginning of almost all reads begins with TATA (the UMI linker).\n",
    "    1. Some reads include the UMI as well, but some libraries don't have it.\n",
    "3. There are millions of duplicated sequences (sometimes >60%)!\n",
    "4. There are PolyA tails.\n",
    "5. It looks like the adapter sequences have already been trimmed (see below). \n",
    "\n",
    "From the [paper](https://journals.plos.org/plospathogens/article?id=10.1371/journal.ppat.1012268#sec010), we know that they used the QuantSeq 3' mRNA FWD V2 library prep kit. You can read a bit about the kit [here](https://www.lexogen.com/store/quantseq-3-mrna-seq-v2-fwd-with-udi/). This kit is optimized for a few things:\n",
    "\n",
    "- Degraded mRNA - it will only get sequences from the 3' end (and PolyA tails)\n",
    "- Low input RNA - which is often the case for small eukaryotic parasites, especially when working with eggs, which are difficult to get RNA out of\n",
    "\n",
    "Typically, manufacturers will provide some guidance on how to trim and filter sequences produced from their kit. For Lexogen (the maker of the QuantSeq kit), this information can be found in the [FAQs](https://faqs.lexogen.com/faq/what-sequences-should-be-trimmed). This site shows that `AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC` is the adapter sequence. Is that sequence (or one like it) in the \"Overrepresented sequences\" section? If so, we need to trim the adapter. If not, we just need to trim the PolyA tail. We'll deal with duplicates later.\n",
    "\n",
    "Remember how libraries are prepared. Each read may include a 6 nt UDI, a 4 nt (TATA) linker, the insert, the PolyA tail, and then the adapter. Based on our QC data, it looks like the adapters have been trimmed (`AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC` isn't overrepresented). The PolyA tail *may* have been trimmed, but it's not obvious - we still see up to 40% PolyA at position 59 in SRR26691093. On the other side of the read, we see TATA in all 4 files, and SRR26691093 and SRR26691087 contain the 6 nt UDI while SRR26691085 and SRR26691082 do not.\n",
    "\n",
    "We definitely want to trim PolyA tails, but trimming UDIs and linkers actually depends on the type of aligner being used. STAR (the aligner we'll be using) can soft-clip the ends of reads that have a high mismatch rate. This also means that we don't need to trim low-quality bases, because they can also be soft-clipped. What about the duplicates? Again, those can be marked during alignment, so we don't need to remove them either.\n",
    "\n",
    "In the end, we'll just trim PolyA tails and do some trimming that's particular to NextSeq that we're not going to get into. We will use the tool [cutadapt](https://cutadapt.readthedocs.io/en/stable/) to perform the trimming. First, check out the manual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456227c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cutadapt --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93759e31",
   "metadata": {},
   "source": [
    "Edit this block and define the result of each of flags used in the above commands.\n",
    "\n",
    "`-j`: \n",
    "\n",
    "`-m`: \n",
    "\n",
    "`-O`:\n",
    "\n",
    "`-a`:\n",
    "\n",
    "`-n`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f32940",
   "metadata": {},
   "source": [
    "We're not actually going to use these options, but it's good to get used to searching tool manuals and deeply understanding each available option/flag. \n",
    "\n",
    "Now let's trim and run QC on these new files to see how they look. We'll use a bash loop again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caf4c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /data/users/wheelenj/biol343/fastq\n",
    "%mkdir trimmed\n",
    "!for fastq in *.fastq.gz; do \\\n",
    "    cutadapt -j 16 -m 20 --poly-a --nextseq-trim=10 -o ./trimmed/$fastq $fastq; \\\n",
    "    done\n",
    "!fastqc -t 16 ./trimmed/*.fastq.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662fe5f5",
   "metadata": {},
   "source": [
    "Open up the QC files from before/after trimming and compare them. Are they looking better? \n",
    "\n",
    "You'll notice that the \"Sequence Length Distribution\" section went from ✅ to ❌. That's because the trimmed PolyA tail was different for each read, so now we have a broad distribution of lengths rather than all of them being 69 nt. \n",
    "\n",
    "Even though we don't have adapters, we still have have overrepresented sequences. What are they? BLAST them against a nucleotide database and see if they are concerning or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9739640e",
   "metadata": {},
   "source": [
    "# Alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee010d6",
   "metadata": {},
   "source": [
    "We will be using STAR (the same tool the authors used) to align RNA-seq reads to the reference genome. STAR has a number of advantages over other aligners:\n",
    "\n",
    "1. Ultra-fast\n",
    "2. Can deal with UMIs/linkers/errors at the ends of reads\n",
    "3. Splice-aware\n",
    "\n",
    "To allow it to be splice-aware (align across splice junctions, with large gaps corresponding to introns), we need to generate a genome index that incorporates the annotations (GTF) and the sequences. We will be using the [STAR manual](https://github.com/alexdobin/STAR/blob/master/doc/STARmanual.pdf) heavily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179e0189",
   "metadata": {},
   "source": [
    "## Index the genome\n",
    "\n",
    "From the manual:\n",
    "\n",
    "The basic options to generate genome indices are as follows:\n",
    "```\n",
    "--runThreadN NumberOfThreads\n",
    "--runMode genomeGenerate\n",
    "--genomeDir /path/to/genomeDir\n",
    "--genomeFastaFiles /path/to/genome/fasta1 /path/to/genome/fasta2 ...\n",
    "--sjdbGTFfile /path/to/annotations.gtf\n",
    "--sjdbOverhang ReadLength-1\n",
    "```\n",
    "\n",
    "Most of these are self-explanatory, but `--sjdbOverhang` takes special consideration. Here's the desription:\n",
    "\n",
    "> `--sjdbOverhang` specifies the length of the genomic sequence around the annotated junction\n",
    "to be used in constructing the splice junctions database. Ideally, this length should be equal\n",
    "to the ReadLength-1, where ReadLength is the length of the reads. For instance, for Illumina\n",
    "2x100b paired-end reads, the ideal value is 100-1=99. In case of reads of varying length, the\n",
    "ideal value is max(ReadLength)-1. In most cases, the default value of 100 will work as\n",
    "well as the ideal value.\n",
    "\n",
    "Usings this description and what we know about our read lenghs from our QC, choose the best value. Edit and run the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fac0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!STAR \\\n",
    "--runThreadN 16 \\\n",
    "--runMode genomeGenerate \\\n",
    "--genomeDir /data/users/wheelenj/biol343/genome \\\n",
    "--genomeFastaFiles /data/users/wheelenj/biol343/genome/genome.fa \\\n",
    "--sjdbGTFfile /data/users/wheelenj/biol343/genome/annotations.gff3 \\\n",
    "--sjdbOverhang 68 \\\n",
    "--genomeSAindexNbases 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c01f146",
   "metadata": {},
   "source": [
    "## Mapping\n",
    "Here are the manual instructions for the mapping steps:\n",
    "\n",
    ">The basic options to run a mapping job are as follows:  \n",
    "`--runThreadN` *NumberOfThreads*  \n",
    "`--genomeDir` */path/to/genomeDir*  \n",
    "`--readFilesIn` */path/to/read1 [/path/to/read2 ]*  \n",
    "`--genomeDir` specifies path to the genome directory where genome indices where generated\n",
    "(see Section 2. Generating genome indexes).  \n",
    "`--readFilesIn` name(s) (with path) of the files containing the sequences to be mapped (e.g.\n",
    "RNA-seq FASTQ files). If using Illumina paired-end reads, the read1 and read2 files have to\n",
    "be supplied. STAR can process both FASTA and FASTQ files. Multi-line (i.e. sequence split\n",
    "in multiple lines) FASTA (but not FASTQ) files are supported.  \n",
    "If the read files are compressed, use the `--readFilesCommand` *UncompressionCommand* option,\n",
    "where *UncompressionCommand* is the un-compression command that takes the file name as\n",
    "input parameter, and sends the uncompressed output to stdout. For example, for gzipped\n",
    "files (\\*.gz) use `--readFilesCommand` *zcat* OR `--readFilesCommand` *gunzip -c*. For bzip2compressed files, use `--readFilesCommand` *bunzip2 -c*.\n",
    "\n",
    "Run the mapping step in the code block below. Remember to use the trimmed reads. Let's run separate commands for each input FastQ file. You could also provide them all in one command, but they would the aligned reads would be in a single output file with a distinguisher in the SAM header, which we haven't yet talked about. Speaking of SAM files, we'll also set an option to create BAMs instead of SAMs and to sort these files by coordinate. Finally, we also need to set the `--outFileNamePrefix` to make sure each outfile gets a different. We will make a separate directory to organize the output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd95808",
   "metadata": {},
   "outputs": [],
   "source": [
    "%mkdir /data/users/wheelenj/biol343/mapping\n",
    "\n",
    "!STAR \\\n",
    "--runThreadN 16 \\\n",
    "--runMode alignReads \\\n",
    "--genomeDir /data/users/wheelenj/biol343/genome \\\n",
    "--readFilesIn /data/users/wheelenj/biol343/fastq/SRR26691082_trim1.fastq \\\n",
    "--outSAMtype BAM SortedByCoordinate \\\n",
    "--outFileNamePrefix /data/users/wheelenj/biol343/mapping/SRR26691082_trim1/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0ee551",
   "metadata": {},
   "source": [
    "In section 9 of the STAR manual, it provides guidance for running the so-called 2-pass mapping. In this scheme, the first pass maps to the known splice junctions provided in the GFF3 while the second pass re-maps to known and novel junctions (which are output in `SJ.out.tab`. However, 9.1 recommends that we include the junctions from ***all*** samples, so we need to align the remaining samples first: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5418b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "!STAR \\\n",
    "--runThreadN 16 \\\n",
    "--runMode alignReads \\\n",
    "--genomeDir /data/users/wheelenj/biol343/genome \\\n",
    "--readFilesIn /data/users/wheelenj/biol343/fastq/SRR26691085_trim1.fastq \\\n",
    "--outSAMtype BAM SortedByCoordinate \\\n",
    "--outFileNamePrefix /data/users/wheelenj/biol343/mapping/SRR26691085_trim1/\n",
    "\n",
    "!STAR \\\n",
    "--runThreadN 16 \\\n",
    "--runMode alignReads \\\n",
    "--genomeDir /data/users/wheelenj/biol343/genome \\\n",
    "--readFilesIn /data/users/wheelenj/biol343/fastq/SRR26691087_trim1.fastq \\\n",
    "--outSAMtype BAM SortedByCoordinate \\\n",
    "--outFileNamePrefix /data/users/wheelenj/biol343/mapping/SRR26691087_trim1/\n",
    "\n",
    "!STAR \\\n",
    "--runThreadN 16 \\\n",
    "--runMode alignReads \\\n",
    "--genomeDir /data/users/wheelenj/biol343/genome \\\n",
    "--readFilesIn /data/users/wheelenj/biol343/fastq/SRR26691093_trim1.fastq \\\n",
    "--outSAMtype BAM SortedByCoordinate \\\n",
    "--outFileNamePrefix /data/users/wheelenj/biol343/mapping/SRR26691093_trim1/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9973d89a",
   "metadata": {},
   "source": [
    "Now we run them all again, this time providing the paths to the new splice junctions with `--sjdbFileChrStartEnd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718ed530",
   "metadata": {},
   "outputs": [],
   "source": [
    "!STAR \\\n",
    "--runThreadN 16 \\\n",
    "--runMode alignReads \\\n",
    "--genomeDir /data/users/wheelenj/biol343/genome \\\n",
    "--readFilesIn /data/users/wheelenj/biol343/fastq/SRR26691082_trim1.fastq \\\n",
    "--outSAMtype BAM SortedByCoordinate \\\n",
    "--outFileNamePrefix /data/users/wheelenj/biol343/mapping/SRR26691082_trim1/ \\\n",
    "--sjdbFileChrStartEnd /data/users/wheelenj/biol343/mapping/SRR26691082_trim1/SJ.out.tab \\\n",
    "                      /data/users/wheelenj/biol343/mapping/SRR26691085_trim1/SJ.out.tab \\\n",
    "                      /data/users/wheelenj/biol343/mapping/SRR26691087_trim1/SJ.out.tab \\\n",
    "                      /data/users/wheelenj/biol343/mapping/SRR26691093_trim1/SJ.out.tab\n",
    "\n",
    "!STAR \\\n",
    "--runThreadN 16 \\\n",
    "--runMode alignReads \\\n",
    "--genomeDir /data/users/wheelenj/biol343/genome \\\n",
    "--readFilesIn /data/users/wheelenj/biol343/fastq/SRR26691085_trim1.fastq \\\n",
    "--outSAMtype BAM SortedByCoordinate \\\n",
    "--outFileNamePrefix /data/users/wheelenj/biol343/mapping/SRR2669108_trim1/ \\\n",
    "--sjdbFileChrStartEnd /data/users/wheelenj/biol343/mapping/SRR26691082_trim1/SJ.out.tab \\\n",
    "                      /data/users/wheelenj/biol343/mapping/SRR26691085_trim1/SJ.out.tab \\\n",
    "                      /data/users/wheelenj/biol343/mapping/SRR26691087_trim1/SJ.out.tab \\\n",
    "                      /data/users/wheelenj/biol343/mapping/SRR26691093_trim1/SJ.out.tab\n",
    "\n",
    "!STAR \\\n",
    "--runThreadN 16 \\\n",
    "--runMode alignReads \\\n",
    "--genomeDir /data/users/wheelenj/biol343/genome \\\n",
    "--readFilesIn /data/users/wheelenj/biol343/fastq/SRR26691087_trim1.fastq \\\n",
    "--outSAMtype BAM SortedByCoordinate \\\n",
    "--outFileNamePrefix /data/users/wheelenj/biol343/mapping/SRR26691087_trim1/ \\\n",
    "--sjdbFileChrStartEnd /data/users/wheelenj/biol343/mapping/SRR26691082_trim1/SJ.out.tab \\\n",
    "                      /data/users/wheelenj/biol343/mapping/SRR26691085_trim1/SJ.out.tab \\\n",
    "                      /data/users/wheelenj/biol343/mapping/SRR26691087_trim1/SJ.out.tab \\\n",
    "                      /data/users/wheelenj/biol343/mapping/SRR26691093_trim1/SJ.out.tab\n",
    "\n",
    "!STAR \\\n",
    "--runThreadN 16 \\\n",
    "--runMode alignReads \\\n",
    "--genomeDir /data/users/wheelenj/biol343/genome \\\n",
    "--readFilesIn /data/users/wheelenj/biol343/fastq/SRR26691093_trim1.fastq \\\n",
    "--outSAMtype BAM SortedByCoordinate \\\n",
    "--outFileNamePrefix /data/users/wheelenj/biol343/mapping/SRR26691093_trim1/ \\\n",
    "--sjdbFileChrStartEnd /data/users/wheelenj/biol343/mapping/SRR26691082_trim1/SJ.out.tab \\\n",
    "                      /data/users/wheelenj/biol343/mapping/SRR26691085_trim1/SJ.out.tab \\\n",
    "                      /data/users/wheelenj/biol343/mapping/SRR26691087_trim1/SJ.out.tab \\\n",
    "                      /data/users/wheelenj/biol343/mapping/SRR26691093_trim1/SJ.out.tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7092e253",
   "metadata": {},
   "source": [
    "We're also going to merge these BAMs, just in case. We also create an index, which allows for fast random access of the BAM file, rather than only accessing the beginning or end of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e30f012",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /data/users/wheelenj/biol343/mapping\n",
    "!samtools merge -o merged.bam SRR26691082_trim1/Aligned.sortedByCoord.out.bam \\\n",
    "                              SRR26691085_trim1/Aligned.sortedByCoord.out.bam \\\n",
    "                              SRR26691087_trim1/Aligned.sortedByCoord.out.bam \\\n",
    "                              SRR26691093_trim1/Aligned.sortedByCoord.out.bam\n",
    "!samtools merge merged.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbf1f62",
   "metadata": {},
   "source": [
    "Mapping is now complete! Now onto post-alignment QC..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ca5ecb",
   "metadata": {},
   "source": [
    "# Alignment QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7ef74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /data/users/wheelenj/biol343/\n",
    "!grep Smp_104210 genome/annotations.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3effee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!samtools tview -d T -p SM_V10_Z:64329382 mapping/merged.bam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7568f4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /data/users/wheelenj/biol343/\n",
    "!multiqc ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c30591",
   "metadata": {},
   "source": [
    "IGV of Smp_316760 (a highly expressed VAL). SM_V10_6:17,278,403-17,279,395"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad61a9f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%cd /data/users/wheelenj/biol343/\n",
    "!grep Smp_316760 genome/annotations.gff3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2130761",
   "metadata": {},
   "source": [
    "# Dedup\n",
    "Only done for low-input, low-complexity libraries. Could even compare the results between deduped and raw alignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926c6187",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /data/users/wheelenj/biol343/mapping\n",
    "!picard MarkDuplicates \\\n",
    "      I=SRR26691082_trim1/Aligned.sortedByCoord.out.bam \\\n",
    "      O=SRR26691082_trim1/dedup.bam \\\n",
    "      M=output_duplicate_metrics.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c948d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head SRR26691082_trim1/output_duplicate_metrics.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe8970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /data/users/wheelenj/biol343/mapping\n",
    "!picard MarkDuplicates \\\n",
    "      I=SRR26691085_trim1/Aligned.sortedByCoord.out.bam \\\n",
    "      O=SRR26691085_trim1/dedup.bam \\\n",
    "      M=output_duplicate_metrics.txt\n",
    "\n",
    "!picard MarkDuplicates \\\n",
    "      I=SRR26691087_trim1/Aligned.sortedByCoord.out.bam \\\n",
    "      O=SRR26691087_trim1/dedup.bam \\\n",
    "      M=output_duplicate_metrics.txt\n",
    "\n",
    "!picard MarkDuplicates \\\n",
    "      I=SRR26691093_trim1/Aligned.sortedByCoord.out.bam \\\n",
    "      O=SRR26691093_trim1/dedup.bam \\\n",
    "      M=output_duplicate_metrics.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e9a2d2",
   "metadata": {},
   "source": [
    "# Counting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642e19f7",
   "metadata": {},
   "source": [
    "Convert GFF to GTF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e608eec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /data/users/wheelenj/biol343/mapping\n",
    "%mkdir /data/users/wheelenj/biol343/counts\n",
    "!featureCounts SRR26691082_trim1/dedup.bam SRR26691085_trim1/dedup.bam SRR26691087_trim1/dedup.bam SRR26691093_trim1/dedup.bam -T 16 -a /data/users/wheelenj/biol343/genome/annotations.gtf -g gene_id -G /data/users/wheelenj/biol343/genome/genome.fa -o /data/users/wheelenj/biol343/counts/counts.tsv -M --fraction --ignoreDup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad58650",
   "metadata": {},
   "source": [
    "# Differential expression\n",
    "Need multiple replicates to do this correctly, so will have to align/count all 12 files in the end..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786925cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biol343",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
